{
    "area1": [
        {
        "area": 1,
            "pregunta": "A development team uses a Git-flow branching model. A CodePipeline pipeline must be triggered only when a pull request to the 'main' branch is merged. The pipeline should then run integration tests and deploy to a staging environment. However, the current configuration triggers on every push to any branch. Which combination of actions will solve this with the LEAST operational overhead? / Un equipo de desarrollo usa un modelo de ramas Git-flow. Un pipeline de CodePipeline debe ejecutarse solo cuando se fusiona un pull request a la rama 'main'. Luego, el pipeline debe ejecutar pruebas de integración y desplegar en un entorno de staging. Sin embargo, la configuración actual se dispara con cada push a cualquier rama. ¿Qué combinación de acciones resolverá esto con la MENOR sobrecarga operativa?",
            "opciones": [
                "Create a CodeCommit trigger that invokes a Lambda function to check the branch name and start the pipeline manually using the SDK. / Crear un disparador de CodeCommit que invoque una función Lambda para verificar el nombre de la rama e iniciar el pipeline manualmente usando el SDK.",
                "In CodePipeline's CodeCommit source action, configure a branch filter to only include the 'main' branch. / En la acción de origen de CodeCommit en CodePipeline, configurar un filtro de rama para incluir únicamente la rama 'main'.",
                "Create an EventBridge rule that listens for CodeCommit 'pullRequestStatusChanged' events with a status of 'MERGED' for the 'main' branch, and set the CodePipeline as the target. / Crear una regla de EventBridge que escuche los eventos 'pullRequestStatusChanged' de CodeCommit con estado 'MERGED' para la rama 'main', y establecer el CodePipeline como destino.",
                "Modify the buildspec.yml in CodeBuild to check the CODEBUILD_WEBHOOK_HEAD_REF environment variable and exit the build if it's not 'refs/heads/main'. / Modificar el buildspec.yml en CodeBuild para verificar la variable de entorno CODEBUILD_WEBHOOK_HEAD_REF y salir de la compilación si no es 'refs/heads/main'."
            ],
            "respuesta_correcta": "Create an EventBridge rule that listens for CodeCommit 'pullRequestStatusChanged' events with a status of 'MERGED' for the 'main' branch, and set the CodePipeline as the target. / Crear una regla de EventBridge que escuche los eventos 'pullRequestStatusChanged' de CodeCommit con estado 'MERGED' para la rama 'main', y establecer el CodePipeline como destino.",
            "explicacion": "While a simple branch filter (Option B) triggers on any push to 'main', it doesn't specifically trigger on a PR merge. The most precise and event-driven method is to use EventBridge to listen for the specific PR MERGED event. This avoids running the pipeline on direct pushes to main that might bypass the PR process. Lambda (A) adds unnecessary complexity, and checking in CodeBuild (D) is inefficient as it starts the pipeline only to stop it. / Aunque un filtro de rama simple (Opción B) se activa con cualquier push a 'main', no se activa específicamente en la fusión de un PR. El método más preciso y basado en eventos es usar EventBridge para escuchar el evento específico de PR MERGED. Esto evita ejecutar el pipeline en pushes directos a main que podrían eludir el proceso de PR. Lambda (A) añade complejidad innecesaria, y verificar en CodeBuild (D) es ineficiente ya que inicia el pipeline solo para detenerlo."
        },
        {
            "area": 1,
            "pregunta": "A CodeBuild project building a container image in a VPC is failing with timeout errors during the `docker pull` phase. The project runs in a private subnet with a NAT Gateway. Security groups and NACLs allow all outbound traffic on port 443. The build log shows intermittent 'connection reset by peer' errors when downloading base layers. What is the MOST likely cause of this issue? / Un proyecto de CodeBuild que construye una imagen de contenedor en una VPC está fallando con errores de timeout durante la fase `docker pull`. El proyecto se ejecuta en una subred privada con un NAT Gateway. Los grupos de seguridad y las NACL permiten todo el tráfico saliente por el puerto 443. El registro de compilación muestra errores intermitentes de 'connection reset by peer' al descargar las capas base. ¿Cuál es la causa MÁS probable de este problema?",
            "opciones": [
                "The CodeBuild service role is missing IAM permissions to access Amazon ECR Public Gallery. / Al rol de servicio de CodeBuild le faltan permisos de IAM para acceder a Amazon ECR Public Gallery.",
                "The NAT Gateway's Elastic IP is being rate-limited by the container registry due to a high volume of requests from other resources using the same NAT. / La IP Elástica del NAT Gateway está siendo limitada en su tasa de solicitudes por el registro de contenedores debido a un alto volumen de peticiones de otros recursos que usan el mismo NAT.",
                "The VPC does not have a VPC Gateway Endpoint for Amazon S3, which is required by CodeBuild for accessing build artifacts. / La VPC no tiene un VPC Gateway Endpoint para Amazon S3, que es requerido por CodeBuild para acceder a los artefactos de compilación.",
                "The CodeBuild project is configured with an instance type that has insufficient memory to pull large container layers. / El proyecto de CodeBuild está configurado con un tipo de instancia que tiene memoria insuficiente para descargar capas de contenedor grandes."
            ],
            "respuesta_correcta": "The NAT Gateway's Elastic IP is being rate-limited by the container registry due to a high volume of requests from other resources using the same NAT. / La IP Elástica del NAT Gateway está siendo limitada en su tasa de solicitudes por el registro de contenedores debido a un alto volumen de peticiones de otros recursos que usan el mismo NAT.",
            "explicacion": "Intermittent connection reset errors during pulls from public registries are a classic symptom of network-level rate limiting. Since all traffic from the private subnet exits through a single Elastic IP on the NAT Gateway, external services like Docker Hub see all requests as coming from one IP. If many builds or other resources are running concurrently, this IP can easily hit the registry's anonymous pull rate limits. The other options are less likely: IAM issues (A) would be a consistent 'permission denied' error, S3 endpoint issues (C) would affect artifacts, not external pulls, and memory issues (D) would likely cause a different error message related to process termination."
        },
        {
            "area": 1,
            "pregunta": "You are designing a CI/CD pipeline for a serverless application with multiple Lambda functions and an API Gateway, defined using AWS SAM. The pipeline must deploy to a staging account and, after manual approval, to a production account. The production deployment must be a blue/green deployment to minimize risk. How should you structure the CodeDeploy portion of the pipeline? / Estás diseñando un pipeline de CI/CD para una aplicación sin servidor con múltiples funciones Lambda y una API Gateway, definida con AWS SAM. El pipeline debe desplegar en una cuenta de staging y, tras aprobación manual, en una cuenta de producción. El despliegue de producción debe ser azul/verde para minimizar el riesgo. ¿Cómo deberías estructurar la porción de CodeDeploy del pipeline?",
            "opciones": [
                "Use a single CodeDeploy application with two deployment groups: one for staging (All-at-once) and one for production (Canary10Percent5Minutes). / Usar una única aplicación de CodeDeploy con dos grupos de despliegue: uno para staging (Todo-a-la-vez) y otro para producción (Canary10Percent5Minutes).",
                "Define the deployment preference type as `LambdaCanary10Percent5Minutes` directly in the `template.yaml` file for the production stage. Use cross-account IAM roles for deployment permissions. / Definir el tipo de preferencia de despliegue como `LambdaCanary10Percent5Minutes` directamente en el archivo `template.yaml` para la etapa de producción. Usar roles de IAM entre cuentas para los permisos de despliegue.",
                "Create two separate CodeDeploy applications, one in each account. The production application will have a blue/green deployment configuration. The pipeline will call each application in its respective stage. / Crear dos aplicaciones de CodeDeploy separadas, una en cada cuenta. La aplicación de producción tendrá una configuración de despliegue azul/verde. El pipeline llamará a cada aplicación en su etapa respectiva.",
                "Use the AWS SAM CLI `sam deploy` command with the `--deployment-preference` flag for the staging deployment and the `--codedeploy-deployment-group` flag for the blue/green production deployment. / Usar el comando `sam deploy` de la AWS SAM CLI con la bandera `--deployment-preference` para el despliegue de staging y la bandera `--codedeploy-deployment-group` para el despliegue azul/verde de producción."
            ],
            "respuesta_correcta": "Define the deployment preference type as `LambdaCanary10Percent5Minutes` directly in the `template.yaml` file for the production stage. Use cross-account IAM roles for deployment permissions. / Definir el tipo de preferencia de despliegue como `LambdaCanary10Percent5Minutes` directamente en el archivo `template.yaml` para la etapa de producción. Usar roles de IAM entre cuentas para los permisos de despliegue.",
            "explicacion": "AWS SAM has native integration with CodeDeploy for safe Lambda deployments. By specifying the `DeploymentPreference` property within the SAM template, you can enable canary or linear deployments automatically. This is the most efficient and IaC-native way. The `sam deploy` command in the pipeline's CloudFormation action will respect this property. This avoids managing CodeDeploy applications manually (Option C) and is the standard SAM approach for this scenario. / AWS SAM tiene integración nativa con CodeDeploy para despliegues seguros de Lambda. Al especificar la propiedad `DeploymentPreference` dentro de la plantilla SAM, puedes habilitar despliegues canary o lineales automáticamente. Esta es la forma más eficiente y nativa de IaC. El comando `sam deploy` en la acción de CloudFormation del pipeline respetará esta propiedad. Esto evita la gestión manual de aplicaciones de CodeDeploy (Opción C) y es el enfoque estándar de SAM para este escenario."
        },
        {
            "area": 1,
            "pregunta": "A CodeDeploy deployment to an EC2 Auto Scaling group is failing on the `ApplicationStop` hook for some instances. The script in this hook is designed to gracefully shut down the application, but it sometimes exceeds its 60-second timeout. This is causing the entire deployment to fail. What is the BEST way to make the deployment more resilient to this issue? / Un despliegue de CodeDeploy a un grupo de Auto Scaling de EC2 está fallando en el hook `ApplicationStop` en algunas instancias. El script en este hook está diseñado para apagar la aplicación de forma controlada, pero a veces excede su timeout de 60 segundos. Esto está causando que todo el despliegue falle. ¿Cuál es la MEJOR manera de hacer el despliegue más resiliente a este problema?",
            "opciones": [
                "Increase the timeout for all lifecycle hooks in the `appspec.yml` file to 300 seconds. / Aumentar el timeout para todos los hooks del ciclo de vida en el archivo `appspec.yml` a 300 segundos.",
                "In the `appspec.yml`, under the `ApplicationStop` hook, add a `timeout` property of 300. In the deployment group settings, configure the deployment to ignore `ApplicationStop` failures. / En el `appspec.yml`, bajo el hook `ApplicationStop`, añadir una propiedad `timeout` de 300. En la configuración del grupo de despliegue, configurar el despliegue para ignorar los fallos de `ApplicationStop`.",
                "Modify the `ApplicationStop` script to run as a background process using `nohup` so it returns a success code immediately. / Modificar el script `ApplicationStop` para que se ejecute como un proceso en segundo plano usando `nohup` y así devuelva un código de éxito inmediatamente.",
                "In the CodeDeploy deployment group settings, disable the `ApplicationStop` hook entirely and handle the shutdown process in the `BeforeInstall` hook of the new version. / En la configuración del grupo de despliegue de CodeDeploy, deshabilitar completamente el hook `ApplicationStop` y manejar el proceso de apagado en el hook `BeforeInstall` de la nueva versión."
            ],
            "respuesta_correcta": "In the `appspec.yml`, under the `ApplicationStop` hook, add a `timeout` property of 300. In the deployment group settings, configure the deployment to ignore `ApplicationStop` failures. / En el `appspec.yml`, bajo el hook `ApplicationStop`, añadir una propiedad `timeout` de 300. En la configuración del grupo de despliegue, configurar el despliegue para ignorar los fallos de `ApplicationStop`.",
            "explicacion": "This two-part solution is the most robust. First, you increase the timeout specifically for the problematic hook, which is better than a global increase. Second, `ApplicationStop` runs on the old instances being replaced. A failure here shouldn't necessarily block the deployment of the new version. Configuring the deployment group to ignore these specific failures ensures the new code gets deployed, while still attempting a graceful shutdown. Running as a background process (C) is risky as it provides a false positive. Disabling the hook (D) removes the graceful shutdown capability entirely. / Esta solución de dos partes es la más robusta. Primero, aumentas el timeout específicamente para el hook problemático, lo cual es mejor que un aumento global. Segundo, `ApplicationStop` se ejecuta en las instancias antiguas que están siendo reemplazadas. Un fallo aquí no debería necesariamente bloquear el despliegue de la nueva versión. Configurar el grupo de despliegue para ignorar estos fallos específicos asegura que el nuevo código se despliegue, mientras se sigue intentando un apagado controlado. Ejecutar como un proceso en segundo plano (C) es arriesgado ya que proporciona un falso positivo. Deshabilitar el hook (D) elimina por completo la capacidad de apagado controlado."
        },
        {
            "area": 1,
            "pregunta": "You need to store a third-party API key securely and make it available to a CodeBuild project. The key must be rotated every 90 days. The build process uses this key to upload artifacts to the third-party service. How can you meet these requirements with the highest level of security and automation? / Necesitas almacenar de forma segura una clave de API de terceros y hacerla disponible para un proyecto de CodeBuild. La clave debe rotarse cada 90 días. El proceso de compilación utiliza esta clave para subir artefactos al servicio de terceros. ¿Cómo puedes cumplir estos requisitos con el mayor nivel de seguridad y automatización?",
            "opciones": [
                "Store the key in SSM Parameter Store as a `SecureString`. Grant the CodeBuild role IAM permissions to read the parameter and reference it in the `buildspec.yml`. Manually update the parameter every 90 days. / Almacenar la clave en SSM Parameter Store como un `SecureString`. Otorgar al rol de CodeBuild permisos de IAM para leer el parámetro y referenciarlo en el `buildspec.yml`. Actualizar manualmente el parámetro cada 90 días.",
                "Store the key in AWS Secrets Manager. Configure a Lambda rotation function and a 90-day rotation schedule. In the `buildspec.yml`, reference the secret ARN in the `env/secrets-manager` section. / Almacenar la clave en AWS Secrets Manager. Configurar una función Lambda de rotación y un calendario de rotación de 90 días. En el `buildspec.yml`, referenciar el ARN del secreto en la sección `env/secrets-manager`.",
                "Create a dedicated IAM user with the API key as its credentials. Attach a policy to this user allowing access to the service. Store the IAM access keys in Secrets Manager and retrieve them in the build script. / Crear un usuario de IAM dedicado con la clave de API como sus credenciales. Adjuntar una política a este usuario que permita el acceso al servicio. Almacenar las claves de acceso de IAM en Secrets Manager y recuperarlas en el script de compilación.",
                "Encrypt the API key using a KMS key and store the resulting ciphertext as a file in the CodeCommit repository. Decrypt the file during the build phase using the AWS CLI. / Cifrar la clave de API usando una clave de KMS y almacenar el texto cifrado resultante como un archivo en el repositorio de CodeCommit. Descifrar el archivo durante la fase de compilación usando la AWS CLI."
            ],
            "respuesta_correcta": "Store the key in AWS Secrets Manager. Configure a Lambda rotation function and a 90-day rotation schedule. In the `buildspec.yml`, reference the secret ARN in the `env/secrets-manager` section. / Almacenar la clave en AWS Secrets Manager. Configurar una función Lambda de rotación y un calendario de rotación de 90 días. En el `buildspec.yml`, referenciar el ARN del secreto en la sección `env/secrets-manager`.",
            "explicacion": "Secrets Manager is the superior choice over SSM Parameter Store because of its built-in, automated rotation capabilities. By creating a Lambda function that knows how to rotate the third-party key, you fully automate the process. CodeBuild's native integration with Secrets Manager (`env/secrets-manager`) is the most secure way to inject the secret into the build environment. Storing credentials in Git (D), even encrypted, is an anti-pattern. / Secrets Manager es la opción superior a SSM Parameter Store debido a sus capacidades de rotación integradas y automatizadas. Al crear una función Lambda que sabe cómo rotar la clave de terceros, automatizas completamente el proceso. La integración nativa de CodeBuild con Secrets Manager (`env/secrets-manager`) es la forma más segura de inyectar el secreto en el entorno de compilación. Almacenar credenciales en Git (D), incluso cifradas, es un antipatrón."
        },
        {
            "area": 1,
            "pregunta": "An ECS Blue/Green deployment managed by CodeDeploy fails during the `Install` step. The CodeDeploy agent log on the EC2 instance shows an error: 'The Docker daemon is not running'. This is an intermittent issue. What is the MOST reliable way to ensure the Docker daemon is running before CodeDeploy attempts to pull the new image? / Un despliegue Azul/Verde de ECS gestionado por CodeDeploy falla durante el paso `Install`. El registro del agente de CodeDeploy en la instancia EC2 muestra un error: 'El demonio de Docker no está en ejecución'. Este es un problema intermitente. ¿Cuál es la forma MÁS fiable de asegurar que el demonio de Docker esté en ejecución antes de que CodeDeploy intente descargar la nueva imagen?",
            "opciones": [
                "Add a `systemctl start docker` command to the `BeforeInstall` hook in the `appspec.yml` file. / Añadir un comando `systemctl start docker` al hook `BeforeInstall` en el archivo `appspec.yml`.",
                "Modify the EC2 instance User Data to include `systemctl enable --now docker` to ensure it starts on boot. / Modificar los User Data de la instancia EC2 para incluir `systemctl enable --now docker` y asegurar que se inicie en el arranque.",
                "Use an SSM State Manager association with the `AWS-RunShellScript` document to run `systemctl status docker` every 5 minutes and restart it if it's not active. / Usar una asociación de SSM State Manager con el documento `AWS-RunShellScript` para ejecutar `systemctl status docker` cada 5 minutos y reiniciarlo si no está activo.",
                "Create a custom AMI with a hardened OS and the Docker daemon pre-configured and enabled. Use this AMI for the EC2 launch template. / Crear una AMI personalizada con un SO reforzado y el demonio de Docker preconfigurado y habilitado. Usar esta AMI para la plantilla de lanzamiento de EC2."
            ],
            "respuesta_correcta": "Use an SSM State Manager association with the `AWS-RunShellScript` document to run `systemctl status docker` every 5 minutes and restart it if it's not active. / Usar una asociación de SSM State Manager con el documento `AWS-RunShellScript` para ejecutar `systemctl status docker` cada 5 minutos y reiniciarlo si no está activo.",
            "explicacion": "Since the issue is intermittent, it implies the daemon is crashing after boot. Therefore, User Data (B) or a custom AMI (D) might not solve the problem if the daemon stops later. An `appspec.yml` hook (A) only runs during a deployment, so it can't fix a daemon that crashed between deployments. SSM State Manager is designed for this exact purpose: to enforce a desired state (like a running service) on a fleet of instances continuously and automatically. This is the most resilient and proactive solution. / Dado que el problema es intermitente, implica que el demonio se está cayendo después del arranque. Por lo tanto, los User Data (B) o una AMI personalizada (D) podrían no resolver el problema si el demonio se detiene más tarde. Un hook de `appspec.yml` (A) solo se ejecuta durante un despliegue, por lo que no puede arreglar un demonio que se cayó entre despliegues. SSM State Manager está diseñado exactamente para este propósito: hacer cumplir un estado deseado (como un servicio en ejecución) en una flota de instancias de forma continua y automática. Esta es la solución más resiliente y proactiva."
        },
        {
            "area": 1,
            "pregunta": "You are creating a single CodePipeline to handle deployments for about 50 microservices. Each microservice has its own CodeCommit repository. A commit to any of these repositories should trigger the pipeline, which will then build the specific service's container image and deploy it. What is the MOST scalable way to configure the pipeline's source stage? / Estás creando un único CodePipeline para gestionar los despliegues de unos 50 microservicios. Cada microservicio tiene su propio repositorio en CodeCommit. Un commit a cualquiera de estos repositorios debería activar el pipeline, que luego construirá la imagen de contenedor del servicio específico y la desplegará. ¿Cuál es la forma MÁS escalable de configurar la etapa de origen del pipeline?",
            "opciones": [
                "Create 50 separate source actions in the pipeline, one for each CodeCommit repository. / Crear 50 acciones de origen separadas en el pipeline, una por cada repositorio de CodeCommit.",
                "Create a single source action that points to a 'manifest' repository. A commit to a microservice repository triggers a Lambda function to update a file in the manifest repository, which in turn triggers the pipeline. / Crear una única acción de origen que apunte a un repositorio de 'manifiesto'. Un commit a un repositorio de microservicio activa una función Lambda para actualizar un archivo en el repositorio de manifiesto, lo que a su vez activa el pipeline.",
                "Use a single CodeCommit source action and configure an EventBridge rule with a complex event pattern that matches commits from all 50 repositories. The rule's target will be the CodePipeline. / Usar una única acción de origen de CodeCommit y configurar una regla de EventBridge con un patrón de evento complejo que coincida con los commits de los 50 repositorios. El destino de la regla será el CodePipeline.",
                "This architecture is flawed. Create 50 separate CodePipelines, one for each microservice, using a shared CloudFormation template for standardization. / Esta arquitectura es defectuosa. Crear 50 CodePipelines separados, uno para cada microservicio, usando una plantilla de CloudFormation compartida para la estandarización."
            ],
            "respuesta_correcta": "This architecture is flawed. Create 50 separate CodePipelines, one for each microservice, using a shared CloudFormation template for standardization. / Esta arquitectura es defectuosa. Crear 50 CodePipelines separados, uno para cada microservicio, usando una plantilla de CloudFormation compartida para la estandarización.",
            "explicacion": "A single pipeline for many microservices (a 'monopipeline') is an anti-pattern. It creates contention, complex logic to determine which service to build, and makes tracking deployments difficult. The best practice for microservices is to have one pipeline per service. This provides isolation, independent deployability, and clear traceability. Using CloudFormation or another IaC tool to stamp out these pipelines from a template makes this approach scalable and manageable. / Un único pipeline para muchos microservicios (un 'monopipeline') es un antipatrón. Crea contención, lógica compleja para determinar qué servicio construir y dificulta el seguimiento de los despliegues. La mejor práctica para microservicios es tener un pipeline por servicio. Esto proporciona aislamiento, capacidad de despliegue independiente y trazabilidad clara. Usar CloudFormation u otra herramienta de IaC para crear estos pipelines a partir de una plantilla hace que este enfoque sea escalable y manejable."
        },
        {
            "area": 1,
            "pregunta": "A CodeBuild project needs to run integration tests that require access to an RDS database in a private subnet. The CodeBuild project itself is also configured to run within the same VPC. The build fails with a database connection timeout. The security group for CodeBuild allows all outbound traffic. The security group for RDS allows inbound traffic on the database port from the CodeBuild security group. What is the MOST likely misconfiguration? / Un proyecto de CodeBuild necesita ejecutar pruebas de integración que requieren acceso a una base de datos RDS en una subred privada. El proyecto de CodeBuild también está configurado para ejecutarse dentro de la misma VPC. La compilación falla con un timeout de conexión a la base de datos. El grupo de seguridad de CodeBuild permite todo el tráfico saliente. El grupo de seguridad de RDS permite el tráfico entrante en el puerto de la base de datos desde el grupo de seguridad de CodeBuild. ¿Cuál es la configuración errónea MÁS probable?",
            "opciones": [
                "The CodeBuild project is running in a public subnet, and the RDS instance is in a private subnet, and there is no route between them. / El proyecto de CodeBuild se está ejecutando en una subred pública, y la instancia de RDS está en una subred privada, y no hay una ruta entre ellas.",
                "The IAM role for CodeBuild does not have the `rds-db:connect` permission required for IAM database authentication. / El rol de IAM para CodeBuild no tiene el permiso `rds-db:connect` requerido para la autenticación de base de datos de IAM.",
                "The subnets specified in the CodeBuild VPC configuration do not have a route to the subnets where the RDS database is located in the VPC route tables. / Las subredes especificadas en la configuración de VPC de CodeBuild no tienen una ruta a las subredes donde se encuentra la base de datos RDS en las tablas de enrutamiento de la VPC.",
                "The security group for the RDS instance is missing an outbound rule to allow traffic back to the CodeBuild security group. / Al grupo de seguridad de la instancia de RDS le falta una regla de salida para permitir el tráfico de vuelta al grupo de seguridad de CodeBuild."
            ],
            "respuesta_correcta": "The subnets specified in the CodeBuild VPC configuration do not have a route to the subnets where the RDS database is located in the VPC route tables. / Las subredes especificadas en la configuración de VPC de CodeBuild no tienen una ruta a las subredes donde se encuentra la base de datos RDS en las tablas de enrutamiento de la VPC.",
            "explicacion": "Security groups are stateful; if inbound traffic is allowed, the return traffic is automatically allowed, so (D) is incorrect. IAM authentication (B) would result in an access denied error, not a timeout. Even if CodeBuild and RDS are in the same VPC, if their respective subnets do not have routes to each other in the VPC's route tables, the packets will be dropped, resulting in a connection timeout. This is a common networking misconfiguration. / Los grupos de seguridad son 'stateful'; si se permite el tráfico de entrada, el tráfico de retorno se permite automáticamente, por lo que (D) es incorrecto. La autenticación de IAM (B) resultaría en un error de acceso denegado, no en un timeout. Incluso si CodeBuild y RDS están en la misma VPC, si sus respectivas subredes no tienen rutas entre sí en las tablas de enrutamiento de la VPC, los paquetes se descartarán, lo que resultará en un timeout de conexión. Esta es una configuración de red errónea muy común."
        },
        {
            "area": 1,
            "pregunta": "You are deploying a critical application to an EKS cluster using a CodePipeline. The deployment strategy must ensure zero downtime and the ability to monitor the new version's performance on a small percentage of live traffic before a full rollout. The deployment process is managed by a Jenkins server integrated with CodePipeline. How should this be implemented? / Estás desplegando una aplicación crítica en un clúster de EKS usando un CodePipeline. La estrategia de despliegue debe asegurar cero tiempo de inactividad y la capacidad de monitorear el rendimiento de la nueva versión en un pequeño porcentaje del tráfico en vivo antes de un despliegue completo. El proceso de despliegue es gestionado por un servidor Jenkins integrado con CodePipeline. ¿Cómo debería implementarse esto?",
            "opciones": [
                "Use CodeDeploy with a blue/green deployment configuration for EKS. The pipeline's Jenkins stage will use `kubectl` to apply the new Kubernetes manifests. / Usar CodeDeploy con una configuración de despliegue azul/verde para EKS. La etapa de Jenkins del pipeline usará `kubectl` para aplicar los nuevos manifiestos de Kubernetes.",
                "In the Jenkins stage, use a canary deployment strategy by manually manipulating Kubernetes Service and Deployment objects. Use a `sleep` command in the Jenkinsfile to create a monitoring window. / En la etapa de Jenkins, usar una estrategia de despliegue canary manipulando manualmente los objetos Service y Deployment de Kubernetes. Usar un comando `sleep` en el Jenkinsfile para crear una ventana de monitoreo.",
                "Integrate the pipeline with a service mesh controller like Istio or App Mesh. The Jenkins stage will deploy the new version, and then use the service mesh's traffic management features to gradually shift a percentage of traffic. / Integrar el pipeline con un controlador de malla de servicios como Istio o App Mesh. La etapa de Jenkins desplegará la nueva versión y luego usará las características de gestión de tráfico de la malla de servicios para desviar gradualmente un porcentaje del tráfico.",
                "Configure the Kubernetes Deployment object with a `RollingUpdate` strategy. Set `maxUnavailable` to 0 and `maxSurge` to 25%. This will be managed automatically by the EKS control plane. / Configurar el objeto Deployment de Kubernetes con una estrategia `RollingUpdate`. Establecer `maxUnavailable` en 0 y `maxSurge` en 25%. Esto será gestionado automáticamente por el plano de control de EKS."
            ],
            "respuesta_correcta": "Integrate the pipeline with a service mesh controller like Istio or App Mesh. The Jenkins stage will deploy the new version, and then use the service mesh's traffic management features to gradually shift a percentage of traffic. / Integrar el pipeline con un controlador de malla de servicios como Istio o App Mesh. La etapa de Jenkins desplegará la nueva versión y luego usará las características de gestión de tráfico de la malla de servicios para desviar gradualmente un porcentaje del tráfico.",
            "explicacion": "A standard Rolling Update (D) provides zero downtime but doesn't allow for a controlled canary analysis phase. A service mesh (C) provides the most powerful and flexible traffic shaping capabilities, allowing you to route a precise percentage of traffic based on advanced rules (like HTTP headers) and monitor the results before proceeding. This is the gold standard for canary deployments in Kubernetes. Manually scripting this in Jenkins (B) is error-prone and complex. CodeDeploy (A) does not natively support EKS deployments; it supports EC2, ECS, and Lambda. / Una Actualización Continua estándar (D) proporciona cero tiempo de inactividad pero no permite una fase de análisis canary controlada. Una malla de servicios (C) proporciona las capacidades de modelado de tráfico más potentes y flexibles, permitiéndote enrutar un porcentaje preciso del tráfico basado en reglas avanzadas (como cabeceras HTTP) y monitorear los resultados antes de continuar. Este es el estándar de oro para los despliegues canary en Kubernetes. Escribir esto manualmente en Jenkins (B) es propenso a errores y complejo. CodeDeploy (A) no soporta de forma nativa los despliegues de EKS; soporta EC2, ECS y Lambda."
        },
        {
            "area": 1,
            "pregunta": "Your organization stores its private Python packages in AWS CodeArtifact. A CodeBuild project needs to install these packages during the `install` phase. The build fails with an authentication error when `pip` tries to connect to the CodeArtifact repository. How should you provide temporary, short-lived credentials to `pip` in the MOST secure and automated way? / Tu organización almacena sus paquetes privados de Python en AWS CodeArtifact. Un proyecto de CodeBuild necesita instalar estos paquetes durante la fase `install`. La compilación falla con un error de autenticación cuando `pip` intenta conectarse al repositorio de CodeArtifact. ¿Cómo deberías proporcionar credenciales temporales y de corta duración a `pip` de la manera MÁS segura y automatizada?",
            "opciones": [
                "Generate a CodeArtifact authorization token using `aws codeartifact get-authorization-token` and store it as a `SecureString` in SSM Parameter Store. Retrieve it in the buildspec. / Generar un token de autorización de CodeArtifact usando `aws codeartifact get-authorization-token` y almacenarlo como un `SecureString` en SSM Parameter Store. Recuperarlo en el buildspec.",
                "Create an IAM user with permissions to CodeArtifact, generate access keys, and add them as environment variables in the CodeBuild project configuration. / Crear un usuario de IAM con permisos para CodeArtifact, generar claves de acceso y añadirlas como variables de entorno en la configuración del proyecto de CodeBuild.",
                "Ensure the CodeBuild service role has the necessary `codeartifact:*` IAM permissions. Then, in the `pre_build` phase of the buildspec, run the `aws codeartifact login` command. / Asegurar que el rol de servicio de CodeBuild tenga los permisos de IAM `codeartifact:*` necesarios. Luego, en la fase `pre_build` del buildspec, ejecutar el comando `aws codeartifact login`.",
                "Configure a VPC endpoint for CodeArtifact and ensure the CodeBuild project runs in a private subnet within that VPC. / Configurar un endpoint de VPC para CodeArtifact y asegurar que el proyecto de CodeBuild se ejecute en una subred privada dentro de esa VPC."
            ],
            "respuesta_correcta": "Ensure the CodeBuild service role has the necessary `codeartifact:*` IAM permissions. Then, in the `pre_build` phase of the buildspec, run the `aws codeartifact login` command. / Asegurar que el rol de servicio de CodeBuild tenga los permisos de IAM `codeartifact:*` necesarios. Luego, en la fase `pre_build` del buildspec, ejecutar el comando `aws codeartifact login`.",
            "explicacion": "The `aws codeartifact login` command is a high-level CLI command designed for this purpose. It automatically fetches a temporary authorization token using the IAM credentials of the execution environment (the CodeBuild role) and configures the package manager (`pip` in this case) to use it. This avoids manual token generation and management (A) and the use of long-lived IAM user keys (B), which is a security anti-pattern. A VPC endpoint (D) provides private connectivity but does not solve the authentication problem. / El comando `aws codeartifact login` es un comando de alto nivel de la CLI diseñado para este propósito. Obtiene automáticamente un token de autorización temporal usando las credenciales de IAM del entorno de ejecución (el rol de CodeBuild) y configura el gestor de paquetes (`pip` en este caso) para usarlo. Esto evita la generación y gestión manual de tokens (A) y el uso de claves de usuario de IAM de larga duración (B), que es un antipatrón de seguridad. Un endpoint de VPC (D) proporciona conectividad privada pero no resuelve el problema de autenticación."
        },
        {
            "area": 1,
            "pregunta": "A CodePipeline is used for deploying infrastructure updates via CloudFormation. A new security requirement mandates that any change that could replace an RDS database or an S3 bucket must be reviewed by a senior engineer before execution. How can this be enforced automatically within the pipeline? / Un CodePipeline se utiliza para desplegar actualizaciones de infraestructura a través de CloudFormation. Un nuevo requisito de seguridad exige que cualquier cambio que pueda reemplazar una base de datos RDS o un bucket de S3 sea revisado por un ingeniero senior antes de la ejecución. ¿Cómo se puede hacer cumplir esto automáticamente dentro del pipeline?",
            "opciones": [
                "Add a manual approval action to the pipeline after the source stage. The senior engineer must review the commit message before approving. / Añadir una acción de aprobación manual al pipeline después de la etapa de origen. El ingeniero senior debe revisar el mensaje del commit antes de aprobar.",
                "In the CloudFormation deploy action, use the 'Create or update a stack' action type and specify a CloudFormation service role that has a deny policy for replacing RDS or S3 resources. / En la acción de despliegue de CloudFormation, usar el tipo de acción 'Crear o actualizar un stack' y especificar un rol de servicio de CloudFormation que tenga una política de denegación para reemplazar recursos de RDS o S3.",
                "Configure the CloudFormation deploy action to first create a Change Set. Add a subsequent action that uses a Lambda function to parse the Change Set. If the Change Set contains a 'Replace' action for an `AWS::RDS::DBInstance` or `AWS::S3::Bucket`, trigger a manual approval action. / Configurar la acción de despliegue de CloudFormation para crear primero un Change Set. Añadir una acción posterior que use una función Lambda para analizar el Change Set. Si el Change Set contiene una acción de 'Reemplazo' para un `AWS::RDS::DBInstance` o `AWS::S3::Bucket`, activar una acción de aprobación manual.",
                "Implement a CloudFormation Stack Policy that denies updates to RDS and S3 resources and apply it to the stack. / Implementar una Política de Stack de CloudFormation que deniegue las actualizaciones a los recursos de RDS y S3 y aplicarla al stack."
            ],
            "respuesta_correcta": "Configure the CloudFormation deploy action to first create a Change Set. Add a subsequent action that uses a Lambda function to parse the Change Set. If the Change Set contains a 'Replace' action for an `AWS::RDS::DBInstance` or `AWS::S3::Bucket`, trigger a manual approval action. / Configurar la acción de despliegue de CloudFormation para crear primero un Change Set. Añadir una acción posterior que use una función Lambda para analizar el Change Set. Si el Change Set contiene una acción de 'Reemplazo' para un `AWS::RDS::DBInstance` o `AWS::S3::Bucket`, activar una acción de aprobación manual.",
            "explicacion": "This is the most precise and automated solution. Creating a Change Set allows the pipeline to preview the changes without executing them. A Lambda function can then programmatically inspect this Change Set for specific, high-risk changes (like 'Replace') and conditionally introduce a manual approval step only when needed. A generic manual approval (A) is not conditional. A deny policy (B) or Stack Policy (D) would block all updates, not just replacements, and wouldn't allow for an approval workflow. / Esta es la solución más precisa y automatizada. La creación de un Change Set permite al pipeline previsualizar los cambios sin ejecutarlos. Una función Lambda puede luego inspeccionar programáticamente este Change Set en busca de cambios específicos de alto riesgo (como 'Reemplazo') e introducir condicionalmente un paso de aprobación manual solo cuando sea necesario. Una aprobación manual genérica (A) no es condicional. Una política de denegación (B) o una Política de Stack (D) bloquearían todas las actualizaciones, no solo los reemplazos, y no permitirían un flujo de trabajo de aprobación."
        },
        {
            "area": 1,
            "pregunta": "An application is deployed using CodeDeploy to a fleet of EC2 instances. The `appspec.yml` file specifies a `ValidateService` hook that runs a health check script. During a deployment, the script fails on 2 out of 10 instances, causing the entire deployment to roll back. The goal is to allow the deployment to succeed even if a small number of health checks fail, but to stop if the failure rate is high. How should the deployment group be configured? / Una aplicación se despliega usando CodeDeploy en una flota de instancias EC2. El archivo `appspec.yml` especifica un hook `ValidateService` que ejecuta un script de verificación de estado. Durante un despliegue, el script falla en 2 de 10 instancias, lo que hace que todo el despliegue se revierta. El objetivo es permitir que el despliegue tenga éxito incluso si un pequeño número de verificaciones de estado fallan, pero detenerlo si la tasa de fallos es alta. ¿Cómo se debe configurar el grupo de despliegue?",
            "opciones": [
                "Modify the `ValidateService` script to have a retry mechanism with exponential backoff. / Modificar el script `ValidateService` para que tenga un mecanismo de reintento con retroceso exponencial.",
                "In the `appspec.yml`, wrap the health check command in a `try-catch` block so the script always exits with a success code. / En el `appspec.yml`, envolver el comando de verificación de estado en un bloque `try-catch` para que el script siempre salga con un código de éxito.",
                "In the CodeDeploy deployment group configuration, set a deployment alarm based on a CloudWatch metric that tracks `ValidateService` failures. / En la configuración del grupo de despliegue de CodeDeploy, establecer una alarma de despliegue basada en una métrica de CloudWatch que rastree los fallos de `ValidateService`.",
                "In the CodeDeploy deployment group configuration, define a minimum healthy hosts rule, such as '90% of hosts' or '8 hosts'. / En la configuración del grupo de despliegue de CodeDeploy, definir una regla de hosts mínimos saludables, como '90% de los hosts' u '8 hosts'."
            ],
            "respuesta_correcta": "In the CodeDeploy deployment group configuration, define a minimum healthy hosts rule, such as '90% of hosts' or '8 hosts'. / En la configuración del grupo de despliegue de CodeDeploy, definir una regla de hosts mínimos saludables, como '90% de los hosts' u '8 hosts'.",
            "explicacion": "The 'minimum healthy hosts' configuration is a core feature of CodeDeploy designed for this exact scenario. It defines the threshold for deployment success. If the number of instances that successfully complete the lifecycle hooks meets this threshold, the overall deployment is considered successful, even if some individual instances fail. This provides deployment resilience. A retry (A) might not fix an underlying issue. Masking failures (B) is dangerous. An alarm (C) is for rollback, not for defining success criteria. / La configuración de 'hosts mínimos saludables' es una característica central de CodeDeploy diseñada para este escenario exacto. Define el umbral para el éxito del despliegue. Si el número de instancias que completan con éxito los hooks del ciclo de vida cumple con este umbral, el despliegue general se considera exitoso, incluso si algunas instancias individuales fallan. Esto proporciona resiliencia al despliegue. Un reintento (A) podría no solucionar un problema subyacente. Enmascarar fallos (B) es peligroso. Una alarma (C) es para la reversión, no para definir criterios de éxito."
        },
        {
            "area": 1,
            "pregunta": "You are building a container image with CodeBuild. The base image is from a public repository, but the application layers contain proprietary code. The final image must be scanned for vulnerabilities before being pushed to a private ECR repository. This process must be automated and fail the build if high-severity vulnerabilities are found. What is the MOST efficient way to integrate this vulnerability scan? / Estás construyendo una imagen de contenedor con CodeBuild. La imagen base es de un repositorio público, pero las capas de la aplicación contienen código propietario. La imagen final debe ser escaneada en busca de vulnerabilidades antes de ser subida a un repositorio privado de ECR. Este proceso debe ser automatizado y hacer que la compilación falle si se encuentran vulnerabilidades de alta gravedad. ¿Cuál es la forma MÁS eficiente de integrar este escaneo de vulnerabilidades?",
            "opciones": [
                "In the `post_build` phase of the `buildspec.yml`, push the image to ECR. Then, use the AWS CLI to describe the image scan findings and parse the JSON output to check for high-severity issues. / En la fase `post_build` del `buildspec.yml`, subir la imagen a ECR. Luego, usar la AWS CLI para describir los resultados del escaneo de la imagen y analizar la salida JSON para buscar problemas de alta gravedad.",
                "Enable 'Enhanced scanning' on the ECR repository, which uses Amazon Inspector. Configure the repository to block pushes of images with high-severity findings. / Habilitar el 'Escaneo mejorado' en el repositorio de ECR, que utiliza Amazon Inspector. Configurar el repositorio para bloquear los pushes de imágenes con hallazgos de alta gravedad.",
                "Integrate a third-party scanning tool like Trivy or Snyk directly into the `build` phase of the `buildspec.yml`. Configure the tool to fail the build based on vulnerability severity. / Integrar una herramienta de escaneo de terceros como Trivy o Snyk directamente en la fase `build` del `buildspec.yml`. Configurar la herramienta para que falle la compilación en función de la gravedad de la vulnerabilidad.",
                "After pushing to ECR, use an EventBridge rule to trigger a Lambda function when an ECR scan completes. The Lambda function will check the findings and, if necessary, delete the image and fail the CodePipeline stage. / Después de subir a ECR, usar una regla de EventBridge para activar una función Lambda cuando se complete un escaneo de ECR. La función Lambda verificará los hallazgos y, si es necesario, eliminará la imagen y hará que falle la etapa de CodePipeline."
            ],
            "respuesta_correcta": "Integrate a third-party scanning tool like Trivy or Snyk directly into the `build` phase of the `buildspec.yml`. Configure the tool to fail the build based on vulnerability severity. / Integrar una herramienta de escaneo de terceros como Trivy o Snyk directamente en la fase `build` del `buildspec.yml`. Configurar la herramienta para que falle la compilación en función de la gravedad de la vulnerabilidad.",
            "explicacion": "This approach provides the tightest feedback loop, a principle of CI/CD known as 'shifting left'. By scanning the image within the build environment *before* it is pushed to any registry, you prevent a vulnerable artifact from ever being stored. Tools like Trivy are fast and can be configured with a simple command to exit with a non-zero code upon finding vulnerabilities, which naturally fails the CodeBuild stage. ECR scanning (A, B, D) happens *after* the image has been pushed, which is too late in the process from a strict security perspective. / Este enfoque proporciona el ciclo de retroalimentación más ajustado, un principio de CI/CD conocido como 'shift left'. Al escanear la imagen dentro del entorno de compilación *antes* de que se suba a cualquier registro, evitas que un artefacto vulnerable se almacene. Herramientas como Trivy son rápidas y se pueden configurar con un simple comando para salir con un código distinto de cero al encontrar vulnerabilidades, lo que naturalmente hace que la etapa de CodeBuild falle. El escaneo de ECR (A, B, D) ocurre *después* de que la imagen ha sido subida, lo cual es demasiado tarde en el proceso desde una perspectiva de seguridad estricta."
        },
        {
            "area": 1,
            "pregunta": "A CodePipeline deploys an ECS service. The pipeline has Source, Build, and Deploy stages. A developer pushes a commit that passes the Build stage but results in a faulty container that fails ECS health checks. The ECS deployment controller initiates a rollback. How can the DevOps team be automatically notified that the deployment rollback occurred, including the specific commit ID that caused the failure? / Un CodePipeline despliega un servicio de ECS. El pipeline tiene etapas de Origen, Construcción y Despliegue. Un desarrollador sube un commit que pasa la etapa de Construcción pero resulta en un contenedor defectuoso que falla las verificaciones de estado de ECS. El controlador de despliegue de ECS inicia una reversión. ¿Cómo se puede notificar automáticamente al equipo de DevOps que ocurrió la reversión del despliegue, incluyendo el ID de commit específico que causó el fallo?",
            "opciones": [
                "Create a CloudWatch Alarm based on the `RunningTaskCount` of the ECS service dropping unexpectedly and send a notification to an SNS topic. / Crear una Alarma de CloudWatch basada en la caída inesperada del `RunningTaskCount` del servicio de ECS y enviar una notificación a un tema de SNS.",
                "In CodePipeline, add a final stage that runs a Lambda function to call the `ecs:DescribeServices` API, check the deployment status, and send a notification if a rollback is detected. / En CodePipeline, añadir una etapa final que ejecute una función Lambda para llamar a la API `ecs:DescribeServices`, verificar el estado del despliegue y enviar una notificación si se detecta una reversión.",
                "Create an EventBridge rule that listens for 'ECS Deployment State Change' events with a `reason` containing 'failed'. The rule target is an SNS topic. The event payload will contain the necessary details. / Crear una regla de EventBridge que escuche los eventos de 'Cambio de Estado de Despliegue de ECS' con una `reason` que contenga 'failed'. El destino de la regla es un tema de SNS. El payload del evento contendrá los detalles necesarios.",
                "Use a CodeDeploy deployment group for the ECS service. CodeDeploy will automatically detect the rollback and fail the pipeline stage, which can be configured to send an SNS notification. / Usar un grupo de despliegue de CodeDeploy para el servicio de ECS. CodeDeploy detectará automáticamente la reversión y hará que falle la etapa del pipeline, que se puede configurar para enviar una notificación a SNS."
            ],
            "respuesta_correcta": "Create an EventBridge rule that listens for 'ECS Deployment State Change' events with a `reason` containing 'failed'. The rule target is an SNS topic. The event payload will contain the necessary details. / Crear una regla de EventBridge que escuche los eventos de 'Cambio de Estado de Despliegue de ECS' con una `reason` que contenga 'failed'. El destino de la regla es un tema de SNS. El payload del evento contendrá los detalles necesarios.",
            "explicacion": "ECS emits detailed events to EventBridge for service state changes, including deployment failures and rollbacks. This is the most direct, real-time, and event-driven method to capture the exact event of a failed deployment. The event payload contains rich contextual information. A CloudWatch alarm (A) is less precise and might trigger for other reasons. Polling from a final pipeline stage (B) is inefficient and not real-time. While CodeDeploy (D) can manage ECS deployments, using the native ECS events is more direct for monitoring the ECS service itself. The commit ID would have to be passed as a variable to the notification system. / ECS emite eventos detallados a EventBridge para los cambios de estado del servicio, incluyendo fallos de despliegue y reversiones. Este es el método más directo, en tiempo real y basado en eventos para capturar el evento exacto de un despliegue fallido. El payload del evento contiene información contextual rica. una Alarma de CloudWatch (A) es menos precisa y podría activarse por otras razones. Sondear desde una etapa final del pipeline (B) es ineficiente y no es en tiempo real. Aunque CodeDeploy (D) puede gestionar despliegues de ECS, usar los eventos nativos de ECS es más directo para monitorear el servicio de ECS en sí. El ID del commit tendría que ser pasado como una variable al sistema de notificación."
        },
        {
            "area": 1,
            "pregunta": "A company is migrating from Jenkins to AWS CodeBuild. They have a complex build process that relies on several custom shell scripts and binary tools that are not present in the standard CodeBuild images. Builds must be as fast as possible. What is the MOST performant and maintainable solution for this migration? / Una empresa está migrando de Jenkins a AWS CodeBuild. Tienen un proceso de compilación complejo que depende de varios scripts de shell personalizados y herramientas binarias que no están presentes en las imágenes estándar de CodeBuild. Las compilaciones deben ser lo más rápidas posible. ¿Cuál es la solución MÁS performante y mantenible para esta migración?",
            "opciones": [
                "In the `install` phase of the `buildspec.yml` for every build, download and install all the required tools and scripts from an S3 bucket. / En la fase `install` del `buildspec.yml` para cada compilación, descargar e instalar todas las herramientas y scripts necesarios desde un bucket de S3.",
                "Create a custom Docker image that contains all the required tools and scripts. Store this image in ECR and specify it as the compute environment for the CodeBuild project. / Crear una imagen de Docker personalizada que contenga todas las herramientas y scripts necesarios. Almacenar esta imagen en ECR y especificarla como el entorno de cómputo para el proyecto de CodeBuild.",
                "Store the tools and scripts in a CodeCommit repository and add a secondary source to the CodeBuild project to check them out into the build environment. / Almacenar las herramientas y scripts en un repositorio de CodeCommit y añadir una fuente secundaria al proyecto de CodeBuild para descargarlos en el entorno de compilación.",
                "Package all the tools into a ZIP file in S3. Use the `secondaryArtifacts` property in the CodeBuild project to download and extract them automatically. / Empaquetar todas las herramientas en un archivo ZIP en S3. Usar la propiedad `secondaryArtifacts` en el proyecto de CodeBuild para descargarlos y extraerlos automáticamente."
            ],
            "respuesta_correcta": "Create a custom Docker image that contains all the required tools and scripts. Store this image in ECR and specify it as the compute environment for the CodeBuild project. / Crear una imagen de Docker personalizada que contenga todas las herramientas y scripts necesarios. Almacenar esta imagen en ECR y especificarla como el entorno de cómputo para el proyecto de CodeBuild.",
            "explicacion": "Using a custom Docker image is the most performant solution because the build environment starts with all dependencies pre-installed, completely eliminating the time-consuming `install` phase. This also leads to more reliable and consistent builds. Downloading tools on every run (A) is slow and inefficient. While using a secondary source (C) or artifacts (D) works, it's still slower than having the tools baked into the image, as they still need to be downloaded at the start of the build. / Usar una imagen de Docker personalizada es la solución más performante porque el entorno de compilación se inicia con todas las dependencias preinstaladas, eliminando por completo la lenta fase de `install`. Esto también conduce a compilaciones más fiables y consistentes. Descargar herramientas en cada ejecución (A) es lento e ineficiente. Aunque usar una fuente secundaria (C) o artefactos (D) funciona, sigue siendo más lento que tener las herramientas integradas en la imagen, ya que todavía necesitan ser descargadas al inicio de la compilación."
        },
        {
            "area": 1,
            "pregunta": "You're deploying a Lambda function using a Blue/Green strategy with AWS SAM and CodeDeploy. The `template.yaml` specifies a `Linear10PercentEvery1Minute` deployment preference. After deployment, CloudWatch alarms indicate a high error rate for the new Lambda version. The automated rollback is triggered. What happens to the Lambda alias (e.g., 'live') during this process? / Estás desplegando una función Lambda usando una estrategia Azul/Verde con AWS SAM y CodeDeploy. El `template.yaml` especifica una preferencia de despliegue `Linear10PercentEvery1Minute`. Después del despliegue, las alarmas de CloudWatch indican una alta tasa de errores para la nueva versión de Lambda. Se activa la reversión automática. ¿Qué le sucede al alias de Lambda (p. ej., 'live') durante este proceso?",
            "opciones": [
                "The 'live' alias is deleted, and traffic is routed directly to the last known good version's ARN. / El alias 'live' se elimina, y el tráfico se enruta directamente al ARN de la última versión buena conocida.",
                "The 'live' alias continues to point to the new, faulty version, but CodeDeploy updates the API Gateway to point to the old version. / El alias 'live' continúa apuntando a la nueva versión defectuosa, pero CodeDeploy actualiza la API Gateway para que apunte a la versión antigua.",
                "The 'live' alias, which was gradually shifting traffic to the new version, is immediately pointed back entirely to the original, stable Lambda version. / El alias 'live', que estaba desviando gradualmente el tráfico a la nueva versión, se vuelve a apuntar inmediatamente por completo a la versión original y estable de Lambda.",
                "A new alias named 'live_rollback' is created and pointed to the stable version, and the pipeline must be manually updated to use it. / Se crea un nuevo alias llamado 'live_rollback' y se apunta a la versión estable, y el pipeline debe actualizarse manualmente para usarlo."
            ],
            "respuesta_correcta": "The 'live' alias, which was gradually shifting traffic to the new version, is immediately pointed back entirely to the original, stable Lambda version. / El alias 'live', que estaba desviando gradualmente el tráfico a la nueva versión, se vuelve a apuntar inmediatamente por completo a la versión original y estable de Lambda.",
            "explicacion": "During a CodeDeploy Lambda deployment, a weighted alias is used to shift traffic. When an alarm triggers a rollback, CodeDeploy's primary action is to update the routing configuration of this same alias, shifting 100% of the weight back to the original stable version. This instantly stops traffic from hitting the faulty version. The alias itself is not deleted or renamed. / Durante un despliegue de Lambda con CodeDeploy, se utiliza un alias con ponderación para desviar el tráfico. Cuando una alarma activa una reversión, la acción principal de CodeDeploy es actualizar la configuración de enrutamiento de este mismo alias, devolviendo el 100% del peso a la versión estable original. Esto detiene instantáneamente el tráfico que llega a la versión defectuosa. El alias en sí no se elimina ni se renombra."
        },
        {
            "area": 1,
            "pregunta": "A pipeline needs to deploy a CloudFormation stack to three different AWS regions (us-east-1, eu-west-1, ap-southeast-2) in parallel for a disaster recovery setup. How can this be modeled in CodePipeline? / Un pipeline necesita desplegar un stack de CloudFormation en tres regiones diferentes de AWS (us-east-1, eu-west-1, ap-southeast-2) en paralelo para una configuración de recuperación de desastres. ¿Cómo se puede modelar esto en CodePipeline?",
            "opciones": [
                "Create a single 'Deploy' stage with three separate actions, each action configured with a different region parameter. / Crear una única etapa de 'Despliegue' con tres acciones separadas, cada una configurada con un parámetro de región diferente.",
                "Use a CloudFormation StackSet action in the Deploy stage. The StackSet will be configured to deploy to the specified regions. / Usar una acción de CloudFormation StackSet en la etapa de Despliegue. El StackSet se configurará para desplegar en las regiones especificadas.",
                "Create three separate 'Deploy' stages, one for each region. The pipeline will execute these stages sequentially. / Crear tres etapas de 'Despliegue' separadas, una para cada región. El pipeline ejecutará estas etapas secuencialmente.",
                "Invoke a CodeBuild project that uses the AWS CLI to run `aws cloudformation deploy` three times with different `--region` flags. / Invocar un proyecto de CodeBuild que use la AWS CLI para ejecutar `aws cloudformation deploy` tres veces con diferentes banderas `--region`."
            ],
            "respuesta_correcta": "Create a single 'Deploy' stage with three separate actions, each action configured with a different region parameter. / Crear una única etapa de 'Despliegue' con tres acciones separadas, cada una configurada con un parámetro de región diferente.",
            "explicacion": "Actions within a single stage in CodePipeline run in parallel by default. Therefore, the most direct and native way to achieve parallel regional deployments is to have one stage containing multiple CloudFormation deployment actions, where each action is explicitly configured for a target region. A StackSet (B) is for deploying across accounts and regions but is managed as a single entity, whereas this asks for parallel actions *within* the pipeline model. Sequential stages (C) would not be parallel. CodeBuild (D) adds an unnecessary layer of scripting. / Las acciones dentro de una misma etapa en CodePipeline se ejecutan en paralelo por defecto. Por lo tanto, la forma más directa y nativa de lograr despliegues regionales en paralelo es tener una etapa que contenga múltiples acciones de despliegue de CloudFormation, donde cada acción está explícitamente configurada para una región de destino. Un StackSet (B) es para desplegar entre cuentas y regiones pero se gestiona como una única entidad, mientras que esto pide acciones paralelas *dentro* del modelo del pipeline. Las etapas secuenciales (C) no serían en paralelo. CodeBuild (D) añade una capa innecesaria de scripting."
        },
        {
            "area": 1,
            "pregunta": "During an EC2/On-Premises deployment, a script in the `BeforeInstall` hook must download a large configuration file from an S3 bucket. The deployment fails intermittently with a timeout error during this step. The instance has an IAM role with the required S3 permissions. What is the MOST likely cause and solution? / Durante un despliegue EC2/On-Premises, un script en el hook `BeforeInstall` debe descargar un archivo de configuración grande desde un bucket de S3. El despliegue falla intermitentemente con un error de timeout durante este paso. La instancia tiene un rol de IAM con los permisos de S3 necesarios. ¿Cuál es la causa y solución MÁS probable?",
            "opciones": [
                "The default timeout for the `BeforeInstall` hook is too short. Increase the timeout for this specific hook in the `appspec.yml` file. / El timeout por defecto para el hook `BeforeInstall` es demasiado corto. Aumentar el timeout para este hook específico en el archivo `appspec.yml`.",
                "The instance is in a private subnet without a route to an S3 VPC Gateway Endpoint, causing traffic to be black-holed. Create an S3 endpoint and add a route. / La instancia está en una subred privada sin una ruta a un VPC Gateway Endpoint de S3, lo que hace que el tráfico se pierda. Crear un endpoint de S3 y añadir una ruta.",
                "The CodeDeploy agent does not have permissions to run the script. Ensure the script has execute permissions (`chmod +x`). / El agente de CodeDeploy no tiene permisos para ejecutar el script. Asegurarse de que el script tenga permisos de ejecución (`chmod +x`).",
                "The IAM instance profile credentials are not being refreshed quickly enough. The script should use the AWS CLI's automatic retry mechanism. / Las credenciales del perfil de instancia de IAM no se están actualizando lo suficientemente rápido. El script debería usar el mecanismo de reintento automático de la AWS CLI."
            ],
            "respuesta_correcta": "The instance is in a private subnet without a route to an S3 VPC Gateway Endpoint, causing traffic to be black-holed. Create an S3 endpoint and add a route. / La instancia está en una subred privada sin una ruta a un VPC Gateway Endpoint de S3, lo que hace que el tráfico se pierda. Crear un endpoint de S3 y añadir una ruta.",
            "explicacion": "An intermittent timeout when accessing AWS services from within a VPC is a classic symptom of a missing VPC endpoint. Without an S3 endpoint, the instance tries to reach the public S3 endpoint via the internet. If the instance is in a private subnet with no NAT Gateway, the traffic has nowhere to go and times out. Adding a Gateway Endpoint for S3 keeps the traffic within the AWS network and provides a reliable route. A short timeout (A) would be a consistent failure, not intermittent. Permission issues (C) would cause a 'permission denied' error, not a timeout. / Un timeout intermitente al acceder a los servicios de AWS desde dentro de una VPC es un síntoma clásico de la falta de un endpoint de VPC. Sin un endpoint de S3, la instancia intenta alcanzar el endpoint público de S3 a través de internet. Si la instancia está en una subred privada sin un NAT Gateway, el tráfico no tiene a dónde ir y se agota el tiempo de espera. Añadir un Gateway Endpoint para S3 mantiene el tráfico dentro de la red de AWS y proporciona una ruta fiable. Un timeout corto (A) sería un fallo consistente, no intermitente. Los problemas de permisos (C) causarían un error de 'permiso denegado', no un timeout."
        },
        {
            "area": 1,
            "pregunta": "A CodePipeline's build stage produces a primary artifact (a large ZIP file) containing compiled code, unit test reports, and deployment scripts. The subsequent 'SecurityScan' stage ONLY needs the compiled code, and the 'PublishReports' stage ONLY needs the test reports. Passing the entire large artifact between stages is inefficient. What is the MOST efficient, native CodePipeline solution? / La etapa de construcción de un CodePipeline produce un artefacto primario (un archivo ZIP grande) que contiene código compilado, informes de pruebas unitarias y scripts de despliegue. La etapa siguiente 'SecurityScan' SÓLO necesita el código compilado, y la etapa 'PublishReports' SÓLO necesita los informes de pruebas. Pasar el artefacto grande completo entre etapas es ineficiente. ¿Cuál es la solución nativa de CodePipeline MÁS eficiente?",
            "opciones": [
              "In the `buildspec.yml`, use the `secondary-artifacts` definition to create separate, smaller output artifacts for the compiled code and reports. Configure the subsequent stages to use these specific artifacts as their input. / En el `buildspec.yml`, usar la definición `secondary-artifacts` para crear artefactos de salida separados y más pequeños para el código compilado y los informes. Configurar las etapas posteriores para usar estos artefactos específicos como su entrada.",
              "Add a Lambda action after the build stage to download the large artifact from S3, split it into smaller ZIP files, and upload them back to S3 for the next stages to use. / Añadir una acción Lambda después de la etapa de construcción para descargar el artefacto grande de S3, dividirlo en archivos ZIP más pequeños y subirlos de nuevo a S3 para que los usen las siguientes etapas.",
              "In each subsequent stage (SecurityScan, PublishReports), add a `pre_build` command to download the large artifact and extract only the necessary files for that stage. / En cada etapa posterior (SecurityScan, PublishReports), añadir un comando `pre_build` para descargar el artefacto grande y extraer solo los archivos necesarios para esa etapa.",
              "Modify the build stage to run three separate CodeBuild projects in parallel: one for the code, one for reports, and one for scripts, each producing its own artifact. / Modificar la etapa de construcción para ejecutar tres proyectos de CodeBuild separados en paralelo: uno para el código, uno para los informes y otro para los scripts, cada uno produciendo su propio artefacto."
            ],
            "respuesta_correcta": "In the `buildspec.yml`, use the `secondary-artifacts` definition to create separate, smaller output artifacts for the compiled code and reports. Configure the subsequent stages to use these specific artifacts as their input. / En el `buildspec.yml`, usar la definición `secondary-artifacts` para crear artefactos de salida separados y más pequeños para el código compilado y los informes. Configurar las etapas posteriores para usar estos artefactos específicos como su entrada.",
            "explicacion": "The `secondary-artifacts` feature in CodeBuild is designed precisely for this use case. It allows a single build execution to produce multiple, distinct artifacts. This is far more efficient than processing a large artifact multiple times (C) or adding the complexity of a custom Lambda function (B). Running parallel builds (D) is unnecessary overhead when a single build can produce all required outputs. / La característica `secondary-artifacts` en CodeBuild está diseñada precisamente para este caso de uso. Permite que una sola ejecución de compilación produzca múltiples artefactos distintos. Esto es mucho más eficiente que procesar un artefacto grande varias veces (C) o añadir la complejidad de una función Lambda personalizada (B). Ejecutar compilaciones en paralelo (D) es una sobrecarga innecesaria cuando una sola compilación puede producir todas las salidas requeridas."
        },
        {
            "area": 1,
            "pregunta": "A CodeDeploy in-place deployment fails on the `DownloadBundle` step for all EC2 instances in a private subnet. The error is 'Access Denied'. You have verified the following: 1) The CodeDeploy service role has `s3:GetObject` on the bucket where revisions are stored. 2) The S3 bucket policy allows access from the CodeDeploy service role. 3) An S3 Gateway VPC Endpoint is attached to the VPC and the route table is correct. What is the MOST likely cause of the 'Access Denied' error? / Un despliegue in-place de CodeDeploy falla en el paso `DownloadBundle` para todas las instancias EC2 en una subred privada. El error es 'Acceso Denegado'. Has verificado lo siguiente: 1) El rol de servicio de CodeDeploy tiene `s3:GetObject` en el bucket donde se almacenan las revisiones. 2) La política del bucket de S3 permite el acceso desde el rol de servicio de CodeDeploy. 3) Un VPC Endpoint de Gateway de S3 está adjunto a la VPC y la tabla de enrutamiento es correcta. ¿Cuál es la causa MÁS probable del error 'Acceso Denegado'?",
            "opciones": [
              "The IAM instance profile attached to the EC2 instances is missing the `s3:GetObject` permission for the revisions bucket. / Al perfil de instancia de IAM adjunto a las instancias EC2 le falta el permiso `s3:GetObject` para el bucket de revisiones.",
              "The S3 Gateway VPC Endpoint policy is too restrictive and does not allow the `s3:GetObject` action from the instances' VPC. / La política del VPC Endpoint de Gateway de S3 es demasiado restrictiva y no permite la acción `s3:GetObject` desde la VPC de las instancias.",
              "The CodeDeploy agent is not installed or running on the EC2 instances. / El agente de CodeDeploy no está instalado o en ejecución en las instancias EC2.",
              "The instances are using an outdated version of the AWS CLI that is not compatible with S3 Gateway Endpoints. / Las instancias están usando una versión desactualizada de la AWS CLI que no es compatible con los VPC Endpoints de Gateway de S3."
            ],
            "respuesta_correcta": "The IAM instance profile attached to the EC2 instances is missing the `s3:GetObject` permission for the revisions bucket. / Al perfil de instancia de IAM adjunto a las instancias EC2 le falta el permiso `s3:GetObject` para el bucket de revisiones.",
            "explicacion": "This is a common point of confusion. The CodeDeploy service role is used by the CodeDeploy service to perform actions *on your behalf*, but the CodeDeploy *agent* runs on the EC2 instance itself. The agent uses the permissions of the attached IAM instance profile to pull the revision bundle from S3. Therefore, even if the service role is correct, the instance profile must also have permissions to download the bundle. A restrictive endpoint policy (B) is possible, but a missing instance profile permission is a more frequent and fundamental cause. Agent issues (C) would typically result in a different error, like 'instance not reachable'. / Este es un punto común de confusión. El rol de servicio de CodeDeploy es utilizado por el servicio CodeDeploy para realizar acciones *en tu nombre*, pero el *agente* de CodeDeploy se ejecuta en la propia instancia EC2. El agente utiliza los permisos del perfil de instancia de IAM adjunto para descargar el paquete de revisión desde S3. Por lo tanto, incluso si el rol de servicio es correcto, el perfil de instancia también debe tener permisos para descargar el paquete. Una política de endpoint restrictiva (B) es posible, pero la falta de permiso en el perfil de instancia es una causa más frecuente y fundamental. Los problemas con el agente (C) normalmente resultarían en un error diferente, como 'instancia no accesible'."
        },
        {
            "area": 1,
            "pregunta": "A buildspec.yml needs to run database migrations, but only for deployments to the 'production' environment. The pipeline passes an environment name ('staging' or 'production') as an environment variable named `DEPLOY_ENV`. Which snippet, placed in the appropriate `buildspec.yml` phase, correctly implements this conditional logic? / Un `buildspec.yml` necesita ejecutar migraciones de base de datos, pero solo para despliegues al entorno de 'producción'. El pipeline pasa un nombre de entorno ('staging' o 'producción') como una variable de entorno llamada `DEPLOY_ENV`. ¿Qué fragmento, colocado en la fase apropiada del `buildspec.yml`, implementa correctamente esta lógica condicional?",
            "opciones": [
              "In the `build` phase: `run-if: $DEPLOY_ENV == \"production\"\ncommands:\n  - echo 'Running migrations...'` / En la fase `build`: `run-if: $DEPLOY_ENV == \"production\"\ncommands:\n  - echo 'Running migrations...'`",
              "In the `post_build` phase: `if [ \"$DEPLOY_ENV\" = \"production\" ]; then\n  echo 'Running migrations...'\nfi` / En la fase `post_build`: `if [ \"$DEPLOY_ENV\" = \"production\" ]; then\n  echo 'Running migrations...'\nfi`",
              "In the `env` section: `variables:\n  RUN_MIGRATIONS: \"$([ \"$DEPLOY_ENV\" = \"production\" ])\"` / En la sección `env`: `variables:\n  RUN_MIGRATIONS: \"$([ \"$DEPLOY_ENV\" = \"production\" ])\"`",
              "In the `pre_build` phase: `conditions:\n  - variable: \"$DEPLOY_ENV\"\n    value: \"production\"\ncommands:\n  - echo 'Running migrations...'` / En la fase `pre_build`: `conditions:\n  - variable: \"$DEPLOY_ENV\"\n    value: \"production\"\ncommands:\n  - echo 'Running migrations...'`"
            ],
            "respuesta_correcta": "In the `post_build` phase: `if [ \"$DEPLOY_ENV\" = \"production\" ]; then\n  echo 'Running migrations...'\nfi` / En la fase `post_build`: `if [ \"$DEPLOY_ENV\" = \"production\" ]; then\n  echo 'Running migrations...'\nfi`",
            "explicacion": "The `buildspec.yml` phases execute standard shell commands. The correct way to implement conditional logic is by using a standard shell `if` statement. The `post_build` phase is a logical place for tasks like migrations that should happen after the main artifact is built. The other options use syntax (`run-if`, `conditions`) that does not exist in the buildspec schema. / Las fases del `buildspec.yml` ejecutan comandos de shell estándar. La forma correcta de implementar lógica condicional es mediante una declaración `if` de shell estándar. La fase `post_build` es un lugar lógico para tareas como las migraciones que deben ocurrir después de que se construye el artefacto principal. Las otras opciones utilizan una sintaxis (`run-if`, `conditions`) que no existe en el esquema del buildspec."
        }
    ],
    "area2": [
        { "area": 2, "pregunta": "You are managing a CloudFormation stack and suspect that a team member has manually changed a resource (e.g., modified a security group rule). What is the most efficient way to identify this unauthorized change? / Estás gestionando un stack de CloudFormation y sospechas que un miembro del equipo ha cambiado manualmente un recurso (ej: ha modificado una regla de un grupo de seguridad). ¿Cuál es la forma más eficiente de identificar este cambio no autorizado?", "opciones": ["Run a new Change Set for the stack / Ejecutar un nuevo Change Set para el stack", "Use AWS Config to track resource changes / Usar AWS Config para rastrear cambios en los recursos", "Use CloudFormation Drift Detection / Usar la Detección de Derivas de CloudFormation", "Manually compare the stack template with the current resources / Comparar manualmente la plantilla del stack con los recursos actuales"], "respuesta_correcta": "Use CloudFormation Drift Detection / Usar la Detección de Derivas de CloudFormation", "explicacion": "Drift Detection is a feature specifically designed to detect when a stack's actual configuration differs from its expected configuration defined in the template. It's the most direct tool for this purpose. / La Detección de Derivas es una característica diseñada específicamente para detectar cuándo la configuración real de un stack difiere de su configuración esperada definida en la plantilla. Es la herramienta más directa para este propósito." },
        { "area": 2, "pregunta": "You need to provide a configuration variable to a fleet of EC2 instances at boot time. The variable is non-sensitive and may be updated occasionally. What is the most suitable AWS Systems Manager feature? / Necesitas proporcionar una variable de configuración a una flota de instancias EC2 en el momento del arranque. La variable no es sensible y puede actualizarse ocasionalmente. ¿Cuál es la característica más adecuada de AWS Systems Manager?", "opciones": ["SSM State Manager", "SSM Parameter Store", "SSM Session Manager", "SSM Distributor"], "respuesta_correcta": "SSM Parameter Store", "explicacion": "Parameter Store is designed to be a centralized store for configuration data. Applications can query the Parameter Store at startup to get the latest configuration values. / Parameter Store está diseñado para ser un almacén centralizado de datos de configuración. Las aplicaciones pueden consultar el Parameter Store al iniciarse para obtener los últimos valores de configuración." },
        { "area": 2, "pregunta": "When creating a CloudFormation template that deploys a Lambda function, how can you reference the function's code stored in an S3 bucket? / Al crear una plantilla de CloudFormation que despliega una función Lambda, ¿cómo puedes referenciar el código de la función almacenado en un bucket de S3?", "opciones": ["Using the 'CodeUri' property / Usando la propiedad 'CodeUri'", "Using the 'Code' property with the S3Bucket and S3Key subproperties / Usando la propiedad 'Code' con las subpropiedades S3Bucket y S3Key", "Using the 'SourceCode' property / Usando la propiedad 'SourceCode'", "Using the 'Package' property with an S3 location / Usando la propiedad 'Package' con una ubicación de S3"], "respuesta_correcta": "Using the 'Code' property with the S3Bucket and S3Key subproperties / Usando la propiedad 'Code' con las subpropiedades S3Bucket y S3Key", "explicacion": "For the AWS::Lambda::Function resource, the 'Code' property is used to specify the location of the deployment package, which includes S3Bucket and S3Key for S3 objects. / Para el recurso AWS::Lambda::Function, se utiliza la propiedad 'Code' para especificar la ubicación del paquete de despliegue, que incluye S3Bucket y S3Key para objetos de S3." },
        { "area": 2, "pregunta": "You want to run a script on a fleet of managed instances at a specific time every day to check for compliance. Which AWS Systems Manager capability should you use? / Quieres ejecutar un script en una flota de instancias gestionadas a una hora específica todos los días para comprobar la conformidad. ¿Qué capacidad de AWS Systems Manager deberías usar?", "opciones": ["SSM Run Command", "SSM Maintenance Windows", "SSM State Manager Association with a schedule / Asociación de SSM State Manager con una programación", "SSM Automation"], "respuesta_correcta": "SSM State Manager Association with a schedule / Asociación de SSM State Manager con una programación", "explicacion": "State Manager is designed to maintain a consistent state. By creating an association with a schedule (e.g., a CRON expression), you can ensure a specific configuration or script is applied repeatedly over time. / State Manager está diseñado para mantener un estado consistente. Al crear una asociación con una programación (ej: una expresión CRON), puedes asegurar que una configuración o script específico se aplique repetidamente a lo largo del tiempo." },
        { "area": 2, "pregunta": "In CloudFormation, what is the purpose of the `DeletionPolicy` attribute? / En CloudFormation, ¿cuál es el propósito del atributo `DeletionPolicy`?", "opciones": ["To specify which resources should be deleted when the stack is updated / Para especificar qué recursos deben eliminarse cuando se actualiza el stack", "To prevent a resource from being accidentally deleted when the stack is deleted / Para evitar que un recurso se elimine accidentalmente cuando se elimina el stack", "To define a custom cleanup script that runs before a resource is deleted / Para definir un script de limpieza personalizado que se ejecuta antes de que se elimine un recurso", "To control the order in which resources are deleted / Para controlar el orden en que se eliminan los recursos"], "respuesta_correcta": "To prevent a resource from being accidentally deleted when the stack is deleted / Para evitar que un recurso se elimine accidentalmente cuando se elimina el stack", "explicacion": "With `DeletionPolicy: Retain`, you can ensure that a resource (like a database or S3 bucket) is preserved even if the CloudFormation stack that created it is deleted. The 'Snapshot' option is also available for certain resources. / Con `DeletionPolicy: Retain`, puedes asegurar que un recurso (como una base de datos o un bucket de S3) se conserve incluso si se elimina el stack de CloudFormation que lo creó. La opción 'Snapshot' también está disponible para ciertos recursos." },
        { "area": 2, "pregunta": "Which CloudFormation intrinsic function should be used to combine multiple strings into a single string? / ¿Qué función intrínseca de CloudFormation debería usarse para combinar múltiples cadenas de texto en una sola?", "opciones": ["Fn::Join", "Fn::Select", "Fn::Sub", "Fn::Merge"], "respuesta_correcta": "Fn::Join", "explicacion": "`Fn::Join` is used to append a set of values into a single value, separated by the specified delimiter. `Fn::Sub` is for substitution, which is different. / `Fn::Join` se utiliza para concatenar un conjunto de valores en un solo valor, separados por el delimitador especificado. `Fn::Sub` es para sustitución, que es diferente." },
        { "area": 2, "pregunta": "You need to patch a large fleet of EC2 instances for a critical vulnerability. What is the most efficient and automated way to do this using AWS Systems Manager? / Necesitas parchear una gran flota de instancias EC2 por una vulnerabilidad crítica. ¿Cuál es la forma más eficiente y automatizada de hacerlo usando AWS Systems Manager?", "opciones": ["Use SSM Run Command to manually run patching scripts on each instance / Usar SSM Run Command para ejecutar manualmente scripts de parcheo en cada instancia", "Use SSM Session Manager to connect to each instance and apply patches / Usar SSM Session Manager para conectarse a cada instancia y aplicar parches", "Use SSM Patch Manager with a 'Scan and Install' operation / Usar SSM Patch Manager con una operación de 'Escanear e Instalar'", "Use SSM Automation to create a custom patching workflow / Usar SSM Automation para crear un flujo de trabajo de parcheo personalizado"], "respuesta_correcta": "Use SSM Patch Manager with a 'Scan and Install' operation / Usar SSM Patch Manager con una operación de 'Escanear e Instalar'", "explicacion": "Patch Manager is the dedicated SSM service for automating the process of patching managed instances. It can scan for missing patches against a defined baseline and automatically install them. / Patch Manager es el servicio de SSM dedicado a automatizar el proceso de parcheo de instancias gestionadas. Puede escanear en busca de parches faltantes contra una línea base definida e instalarlos automáticamente." },
        { "area": 2, "pregunta": "What is a key difference between AWS Secrets Manager and SSM Parameter Store for storing secrets? / ¿Cuál es una diferencia clave entre AWS Secrets Manager y SSM Parameter Store para almacenar secretos?", "opciones": ["Secrets Manager cannot integrate with KMS, while Parameter Store can / Secrets Manager no puede integrarse con KMS, mientras que Parameter Store sí puede", "Secrets Manager provides automated secret rotation, while Parameter Store does not / Secrets Manager proporciona rotación automática de secretos, mientras que Parameter Store no", "Parameter Store can store larger secrets than Secrets Manager / Parameter Store puede almacenar secretos más grandes que Secrets Manager", "Parameter Store is more expensive for storing secrets / Parameter Store es más caro para almacenar secretos"], "respuesta_correcta": "Secrets Manager provides automated secret rotation, while Parameter Store does not / Secrets Manager proporciona rotación automática de secretos, mientras que Parameter Store no", "explicacion": "The flagship feature of Secrets Manager is its native ability to automatically rotate secrets like database credentials, which is a critical security practice not offered by Parameter Store. / La característica principal de Secrets Manager es su capacidad nativa para rotar automáticamente secretos como credenciales de bases de datos, lo cual es una práctica de seguridad crítica no ofrecida por Parameter Store." },
        { "area": 2, "pregunta": "In a CloudFormation template, how do you refer to the value of a resource that has been created within the same template? / En una plantilla de CloudFormation, ¿cómo te refieres al valor de un recurso que ha sido creado dentro de la misma plantilla?", "opciones": ["Using the `!GetAtt` intrinsic function / Usando la función intrínseca `!GetAtt`", "Using the `!Ref` intrinsic function / Usando la función intrínseca `!Ref`", "Using the `!ImportValue` intrinsic function / Usando la función intrínseca `!ImportValue`", "Using the `!FindInMap` intrinsic function / Usando la función intrínseca `!FindInMap`"], "respuesta_correcta": "Using the `!Ref` intrinsic function / Usando la función intrínseca `!Ref`", "explicacion": "`!Ref` is used to get the logical ID or a common value (like an instance ID). `!GetAtt` is used to get other attributes of a resource (like a security group's ID or an S3 bucket's ARN). Both functions are used to reference resources. / `!Ref` se usa para obtener el ID lógico o un valor común (como el ID de una instancia). `!GetAtt` se usa para obtener otros atributos de un recurso (como el ID de un grupo de seguridad o el ARN de un bucket de S3). Ambas funciones se usan para referenciar recursos." },
        { "area": 2, "pregunta": "What is the purpose of a CloudFormation Stack Policy? / ¿Cuál es el propósito de una Política de Stack de CloudFormation?", "opciones": ["To define which IAM users are allowed to manage the stack / Para definir qué usuarios de IAM pueden gestionar el stack", "To prevent updates to critical resources within a stack / Para prevenir actualizaciones a recursos críticos dentro de un stack", "To specify the order of resource creation and deletion / Para especificar el orden de creación y eliminación de recursos", "To validate the parameters passed to the stack / Para validar los parámetros pasados al stack"], "respuesta_correcta": "To prevent updates to critical resources within a stack / Para prevenir actualizaciones a recursos críticos dentro de un stack", "explicacion": "A Stack Policy is a JSON document that gives you explicit control over which resources can be updated during a stack update, protecting them from unintentional changes. / una Política de Stack es un documento JSON que te da control explícito sobre qué recursos pueden ser actualizados durante una actualización del stack, protegiéndolos de cambios no intencionados." },
        { "area": 2, "pregunta": "How can you share information (like a VPC ID or Subnet ID) between two different CloudFormation stacks? / ¿Cómo puedes compartir información (como un ID de VPC o de Subred) entre dos stacks de CloudFormation diferentes?", "opciones": ["By using the `!ImportValue` in one stack and `Export` in the other / Usando `!ImportValue` en un stack y `Export` en el otro", "By hardcoding the values in both templates / Escribiendo directamente los valores en ambas plantillas", "By using Systems Manager Parameter Store to store and retrieve the values / Usando Systems Manager Parameter Store para almacenar y recuperar los valores", "By creating a parent stack that manages both stacks / Creando un stack padre que gestione ambos stacks"], "respuesta_correcta": "By using the `!ImportValue` in one stack and `Export` in the other / Usando `!ImportValue` en un stack y `Export` en el otro", "explicacion": "CloudFormation's cross-stack references feature allows you to export an output value from one stack, and then use `Fn::ImportValue` to use that value in another stack within the same region and account. / La característica de referencias entre stacks de CloudFormation te permite exportar un valor de salida de un stack, y luego usar `Fn::ImportValue` para usar ese valor en otro stack dentro de la misma región y cuenta." },
        { "area": 2, "pregunta": "You want to ensure a group of EC2 instances always has a specific monitoring agent installed and running. What is the most idempotent way to achieve this using SSM? / Quieres asegurar que un grupo de instancias EC2 siempre tenga un agente de monitoreo específico instalado y en ejecución. ¿Cuál es la forma más idempotente de lograrlo usando SSM?", "opciones": ["Schedule an SSM Run Command to install the agent hourly / Programar un SSM Run Command para instalar el agente cada hora", "Create an SSM State Manager Association using the `AWS-ConfigureAWSPackage` document / Crear una Asociación de SSM State Manager usando el documento `AWS-ConfigureAWSPackage`", "Use SSM Distributor to create a package and deploy it manually / Usar SSM Distributor para crear un paquete y desplegarlo manualmente", "Run an SSM Automation document that checks for the agent / Ejecutar un documento de SSM Automation que compruebe si existe el agente"], "respuesta_correcta": "Create an SSM State Manager Association using the `AWS-ConfigureAWSPackage` document / Crear una Asociación de SSM State Manager usando el documento `AWS-ConfigureAWSPackage`", "explicacion": "State Manager is designed to maintain a desired state. By creating an association, it will automatically check and enforce the presence and configuration of software like an agent, making it the most idempotent solution. / State Manager está diseñado para mantener un estado deseado. Al crear una asociación, comprobará y forzará automáticamente la presencia y configuración de software como un agente, convirtiéndola en la solución más idempotente." },
        { "area": 2, "pregunta": "What is a CloudFormation macro? / ¿Qué es una macro de CloudFormation?", "opciones": ["A way to run custom scripts during a stack update / Una forma de ejecutar scripts personalizados durante una actualización de stack", "A feature for performing custom processing on a template before CloudFormation creates the resources / Una característica para realizar un procesamiento personalizado en una plantilla antes de que CloudFormation cree los recursos", "A method for managing stacks across multiple regions / Un método para gestionar stacks en múltiples regiones", "A tool for visualizing the resources in a stack / Una herramienta para visualizar los recursos en un stack"], "respuesta_correcta": "A feature for performing custom processing on a template before CloudFormation creates the resources / Una característica para realizar un procesamiento personalizado en una plantilla antes de que CloudFormation cree los recursos", "explicacion": "Macros, powered by Lambda functions, allow you to perform transformations on your CloudFormation template, from simple string replacements to creating more complex, reusable patterns. / Las macros, impulsadas por funciones Lambda, te permiten realizar transformaciones en tu plantilla de CloudFormation, desde simples reemplazos de texto hasta la creación de patrones más complejos y reutilizables." },
        { "area": 2, "pregunta": "You are using SSM Parameter Store to store an API key. You want to ensure that every change to this key is logged for auditing. How can you achieve this? / Estás usando SSM Parameter Store para almacenar una clave de API. Quieres asegurar que cada cambio a esta clave quede registrado para auditoría. ¿Cómo puedes lograr esto?", "opciones": ["Enable versioning on the parameter / Habilitar el versionado en el parámetro", "Integrate Parameter Store with AWS CloudTrail and Amazon EventBridge / Integrar Parameter Store con AWS CloudTrail y Amazon EventBridge", "Write a Lambda function that polls the parameter for changes / Escribir una función Lambda que sondee el parámetro en busca de cambios", "Store the parameter in a private Git repository instead / Almacenar el parámetro en un repositorio Git privado en su lugar"], "respuesta_correcta": "Integrate Parameter Store with AWS CloudTrail and Amazon EventBridge / Integrar Parameter Store con AWS CloudTrail y Amazon EventBridge", "explicacion": "All Parameter Store API calls are logged by CloudTrail. You can then use EventBridge to create rules that react to specific API calls (like `PutParameter`) to trigger notifications or other audit actions. / Todas las llamadas a la API de Parameter Store son registradas por CloudTrail. Luego puedes usar EventBridge para crear reglas que reaccionen a llamadas a la API específicas (como `PutParameter`) para disparar notificaciones u otras acciones de auditoría." },
        { "area": 2, "pregunta": "What is the purpose of the `cfn-lint` tool? / ¿Cuál es el propósito de la herramienta `cfn-lint`?", "opciones": ["To execute CloudFormation templates from the command line / Para ejecutar plantillas de CloudFormation desde la línea de comandos", "To validate a CloudFormation template against the official AWS specification and best practices / Para validar una plantilla de CloudFormation contra la especificación oficial de AWS y las mejores prácticas", "To convert a CloudFormation template from JSON to YAML / Para convertir una plantilla de CloudFormation de JSON a YAML", "To estimate the cost of the resources defined in a template / Para estimar el costo de los recursos definidos en una plantilla"], "respuesta_correcta": "To validate a CloudFormation template against the official AWS specification and best practices / Para validar una plantilla de CloudFormation contra la especificación oficial de AWS y las mejores prácticas", "explicacion": "`cfn-lint` is an open-source tool that helps you lint or validate your CloudFormation templates before deploying them. This can catch syntax errors, incorrect property values, and other common issues. / `cfn-lint` es una herramienta de código abierto que te ayuda a validar tus plantillas de CloudFormation antes de desplegarlas. Esto puede detectar errores de sintaxis, valores de propiedad incorrectos y otros problemas comunes." },
        { "area": 2, "pregunta": "In an SSM Automation document, what is the purpose of the `aws:executeScript` action? / En un documento de SSM Automation, ¿cuál es el propósito de la acción `aws:executeScript`?", "opciones": ["To run a shell script on a target EC2 instance / Para ejecutar un script de shell en una instancia EC2 de destino", "To execute an AWS API call / Para ejecutar una llamada a la API de AWS", "To execute a Python or PowerShell script directly within the Automation workflow itself / Para ejecutar un script de Python o PowerShell directamente dentro del propio flujo de trabajo de Automation", "To invoke another Automation document / Para invocar otro documento de Automation"], "respuesta_correcta": "To execute a Python or PowerShell script directly within the Automation workflow itself / Para ejecutar un script de Python o PowerShell directamente dentro del propio flujo de trabajo de Automation", "explicacion": "This action allows you to run custom logic (e.g., parsing output, conditional branching) within the automation without needing a separate Lambda function or running commands on an instance. / Esta acción te permite ejecutar lógica personalizada (ej: analizar salidas, ramificación condicional) dentro de la automatización sin necesidad de una función Lambda separada o de ejecutar comandos en una instancia." },
        { "area": 2, "pregunta": "What is a primary use case for CloudFormation StackSets? / ¿Cuál es un caso de uso principal para los StackSets de CloudFormation?", "opciones": ["To deploy the same stack across multiple AWS accounts and regions in a single operation / Para desplegar el mismo stack en múltiples cuentas y regiones de AWS en una sola operación", "To group multiple related stacks into a single manageable unit / Para agrupar múltiples stacks relacionados en una sola unidad manejable", "To test changes to a stack before applying them / Para probar los cambios en un stack antes de aplicarlos", "To automatically roll back a failed stack update / Para revertir automáticamente una actualización de stack fallida"], "respuesta_correcta": "To deploy the same stack across multiple AWS accounts and regions in a single operation / Para desplegar el mismo stack en múltiples cuentas y regiones de AWS en una sola operación", "explicacion": "StackSets extend the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation. This is ideal for deploying baseline resources or common applications. / Los StackSets amplían la funcionalidad de los stacks permitiéndote crear, actualizar o eliminar stacks en múltiples cuentas y regiones con una sola operación. Esto es ideal para desplegar recursos base o aplicaciones comunes." },
        { "area": 2, "pregunta": "You need to update a CloudFormation stack but want to ensure that a critical RDS database is not replaced, only modified. Which resource attribute should you use? / Necesitas actualizar un stack de CloudFormation pero quieres asegurar que una base de datos RDS crítica no sea reemplazada, solo modificada. ¿Qué atributo de recurso deberías usar?", "opciones": ["UpdatePolicy with 'AutoScalingReplacingUpdate' / UpdatePolicy con 'AutoScalingReplacingUpdate'", "CreationPolicy with 'ResourceSignal' / CreationPolicy con 'ResourceSignal'", "UpdateReplacePolicy with 'Retain' / UpdateReplacePolicy con 'Retain'", "DependsOn attribute / Atributo DependsOn"], "respuesta_correcta": "UpdateReplacePolicy with 'Retain' / UpdateReplacePolicy con 'Retain'", "explicacion": "`UpdateReplacePolicy` is similar to `DeletionPolicy` but applies specifically to updates that would cause a resource replacement. Setting it to 'Retain' will prevent CloudFormation from replacing the resource. / `UpdateReplacePolicy` es similar a `DeletionPolicy` pero se aplica específicamente a las actualizaciones que causarían un reemplazo de recurso. Establecerlo en 'Retain' evitará que CloudFormation reemplace el recurso." },
        { "area": 2, "pregunta": "What does the AWS AppConfig service provide that SSM Parameter Store does not? / ¿Qué proporciona el servicio AWS AppConfig que SSM Parameter Store no ofrece?", "opciones": ["The ability to store configuration data / La capacidad de almacenar datos de configuración", "Integration with AWS KMS for encryption / Integración con AWS KMS para el cifrado", "Features for controlled deployments of configuration changes, including validation and rollback / Características para despliegues controlados de cambios de configuración, incluyendo validación y reversión", "The ability to store secrets securely / La capacidad de almacenar secretos de forma segura"], "respuesta_correcta": "Features for controlled deployments of configuration changes, including validation and rollback / Características para despliegues controlados de cambios de configuración, incluyendo validación y reversión", "explicacion": "AppConfig is a full-fledged service for managing and deploying application configuration. It adds a safety layer on top of configuration data (which can be stored in Parameter Store) by enabling validation and gradual rollout strategies. / AppConfig es un servicio completo para gestionar y desplegar la configuración de aplicaciones. Añade una capa de seguridad sobre los datos de configuración (que pueden almacenarse en Parameter Store) al permitir la validación y estrategias de despliegue gradual." },
        { "area": 2, "pregunta": "When using Systems Manager to manage on-premises servers, what is required to register them as managed instances? / Al usar Systems Manager para gestionar servidores on-premises, ¿qué se requiere para registrarlos como instancias gestionadas?", "opciones": ["A direct connection via AWS Direct Connect / Una conexión directa a través de AWS Direct Connect", "An IAM user with administrator access / Un usuario de IAM con acceso de administrador", "Installing the SSM Agent and creating a hybrid activation / Instalar el Agente SSM y crear una activación híbrida", "The on-premises servers must be running Amazon Linux / Los servidores on-premises deben ejecutar Amazon Linux"], "respuesta_correcta": "Installing the SSM Agent and creating a hybrid activation / Instalar el Agente SSM y crear una activación híbrida", "explicacion": "For on-premises servers or non-EC2 virtual machines, you must install the SSM Agent and then create a hybrid activation in the AWS console. This provides an activation code and ID to register the machine with the Systems Manager service. / Para servidores on-premises o máquinas virtuales que no son EC2, debes instalar el Agente SSM y luego crear una activación híbrida en la consola de AWS. Esto proporciona un código de activación y un ID para registrar la máquina con el servicio de Systems Manager." }
    ],
    "area3": [
        { "area": 3, "pregunta": "Your application is behind an Application Load Balancer with targets in multiple Availability Zones. One entire AZ goes down. What is the expected behavior of the ALB if cross-zone load balancing is enabled? / Tu aplicación está detrás de un Application Load Balancer con destinos en múltiples Zonas de Disponibilidad. Una AZ completa se cae. ¿Cuál es el comportamiento esperado del ALB si el balanceo de carga entre zonas está habilitado?", "opciones": ["The ALB will stop routing traffic to all AZs until the failed one recovers / El ALB dejará de enrutar tráfico a todas las AZs hasta que la que falló se recupere", "The ALB will distribute the traffic from the failed AZ proportionally across the remaining healthy instances in the other AZs / El ALB distribuirá el tráfico de la AZ fallida proporcionalmente entre las instancias saludables restantes en las otras AZs", "The ALB will only route traffic to the healthy instances in the unaffected AZs, but the distribution might be uneven / El ALB solo enrutará tráfico a las instancias saludables en las AZs no afectadas, pero la distribución podría ser desigual", "The ALB will terminate all instances and launch new ones in the healthy AZs / El ALB terminará todas las instancias y lanzará nuevas en las AZs saludables"], "respuesta_correcta": "The ALB will distribute the traffic from the failed AZ proportionally across the remaining healthy instances in the other AZs / El ALB distribuirá el tráfico de la AZ fallida proporcionalmente entre las instancias saludables restantes en las otras AZs", "explicacion": "With cross-zone load balancing enabled, the ALB treats all registered instances in all AZs as a single group and distributes traffic evenly among them, regardless of which AZ they are in. If an AZ fails, its traffic is automatically redistributed across the remaining instances. / Con el balanceo de carga entre zonas habilitado, el ALB trata a todas las instancias registradas en todas las AZs como un solo grupo y distribuye el tráfico de manera uniforme entre ellas. Si una AZ falla, su tráfico se redistribuye automáticamente entre las instancias restantes." },
        { "area": 3, "pregunta": "You are designing a disaster recovery strategy with a Recovery Time Objective (RTO) of 15 minutes and a Recovery Point Objective (RPO) of 5 minutes. Which DR strategy is most appropriate? / Estás diseñando una estrategia de recuperación de desastres con un RTO de 15 minutos y un RPO de 5 minutos. ¿Qué estrategia de DR es más apropiada?", "opciones": ["Backup and Restore", "Pilot Light", "Warm Standby", "Multi-site Active/Active"], "respuesta_correcta": "Warm Standby", "explicacion": "Warm Standby involves a scaled-down but fully functional version of your infrastructure in another region. It can meet a 15-minute RTO, and a low RPO can be achieved with asynchronous database replication. Multi-site is too complex/expensive, and Pilot Light is too slow. / Warm Standby implica una versión a escala reducida pero completamente funcional de tu infraestructura en otra región. Puede cumplir un RTO de 15 minutos, y un RPO bajo se puede lograr con replicación de base de datos asíncrona. Multi-sitio es demasiado complejo/caro, y Pilot Light es demasiado lento." },
        { "area": 3, "pregunta": "An Auto Scaling group is configured with a desired capacity of 5, a minimum of 2, and a maximum of 10. The group is currently running 5 healthy instances. An operator manually terminates one of the instances. What happens next? / Un grupo de Auto Scaling está configurado con una capacidad deseada de 5, un mínimo de 2 y un máximo de 10. Actualmente hay 5 instancias saludables. Un operador termina manualmente una de las instancias. ¿Qué sucede a continuación?", "opciones": ["The ASG will terminate another instance to meet the minimum capacity / El ASG terminará otra instancia para cumplir la capacidad mínima", "The ASG will launch a new instance to maintain the desired capacity of 5 / El ASG lanzará una nueva instancia para mantener la capacidad deseada de 5", "Nothing will happen until a scaling policy is triggered / No pasará nada hasta que se dispare una política de escalado", "The ASG will send an SNS notification but will not take action / El ASG enviará una notificación SNS pero no tomará ninguna acción"], "respuesta_correcta": "The ASG will launch a new instance to maintain the desired capacity of 5 / El ASG lanzará una nueva instancia para mantener la capacidad deseada de 5", "explicacion": "The primary purpose of an Auto Scaling group is to maintain the desired number of instances. If an instance is terminated for any reason (health check failure or manual termination), the ASG will automatically launch a replacement. / El propósito principal de un grupo de Auto Scaling es mantener el número deseado de instancias. Si una instancia se termina por cualquier motivo (fallo de health check o terminación manual), el ASG lanzará automáticamente un reemplazo." },
        { "area": 3, "pregunta": "Which Route 53 routing policy is best for a disaster recovery scenario where you want to fail over to a secondary region only when the primary region is unhealthy? / ¿Qué política de enrutamiento de Route 53 es mejor para un escenario de recuperación de desastres en el que deseas conmutar por error a una región secundaria solo cuando la región primaria no está saludable?", "opciones": ["Simple Routing", "Weighted Routing", "Latency-based Routing", "Failover Routing"], "respuesta_correcta": "Failover Routing", "explicacion": "Failover routing is specifically designed for DR. You configure a primary record and a secondary record. Route 53 monitors the health of the primary endpoint and automatically routes traffic to the secondary if the primary becomes unhealthy. / El enrutamiento por conmutación por error está diseñado específicamente para DR. Configuras un registro primario y uno secundario. Route 53 monitorea la salud del endpoint primario y automáticamente enruta el tráfico al secundario si el primario deja de estar saludable." },
        { "area": 3, "pregunta": "To achieve high availability for a stateful application running on EC2, you need a storage solution that is replicated across multiple AZs and can be attached to only one instance at a time. Which service should you use? / Para lograr alta disponibilidad en una aplicación con estado que se ejecuta en EC2, necesitas una solución de almacenamiento que se replique en múltiples AZs y que solo se pueda adjuntar a una instancia a la vez. ¿Qué servicio deberías usar?", "opciones": ["Amazon EFS", "Amazon S3", "Amazon EBS Multi-Attach", "Amazon EBS"], "respuesta_correcta": "Amazon EBS", "explicacion": "Standard EBS volumes are specific to an Availability Zone. However, you can take snapshots and restore them to other AZs. For automatic failover, a common pattern is to snapshot the EBS volume and have a process to restore it and attach it to a new instance in a different AZ. EFS is for multi-attachment. / Los volúmenes EBS estándar son específicos de una Zona de Disponibilidad. Sin embargo, puedes tomar instantáneas y restaurarlas en otras AZs. Para la conmutación por error automática, un patrón común es tomar una instantánea del volumen EBS y tener un proceso para restaurarlo y adjuntarlo a una nueva instancia en una AZ diferente. EFS es para adjuntar a múltiples instancias." },
        { "area": 3, "pregunta": "How does an Amazon RDS Multi-AZ deployment improve database resilience? / ¿Cómo mejora la resiliencia de la base de datos un despliegue Multi-AZ de Amazon RDS?", "opciones": ["It creates read replicas in multiple AZs to improve read performance / Crea réplicas de lectura en múltiples AZs para mejorar el rendimiento de lectura", "It synchronously replicates data to a standby instance in a different AZ and provides automatic failover / Replica sincrónicamente los datos a una instancia de reserva en una AZ diferente y proporciona conmutación por error automática", "It asynchronously replicates data to another region for disaster recovery / Replica asincrónicamente los datos a otra región para la recuperación de desastres", "It automatically scales the database capacity based on load / Escala automáticamente la capacidad de la base de datos según la carga"], "respuesta_correcta": "It synchronously replicates data to a standby instance in a different AZ and provides automatic failover / Replica sincrónicamente los datos a una instancia de reserva en una AZ diferente y proporciona conmutación por error automática", "explicacion": "Multi-AZ is a high-availability feature. It maintains a synchronous standby replica in a different AZ. In case of a primary instance failure, RDS automatically fails over to the standby instance with no data loss (RPO of zero). / Multi-AZ es una característica de alta disponibilidad. Mantiene una réplica de reserva síncrona en una AZ diferente. En caso de fallo de la instancia principal, RDS conmuta automáticamente a la instancia de reserva sin pérdida de datos (RPO de cero)." },
        { "area": 3, "pregunta": "You are using an S3 bucket to store critical data. What is the most effective feature to protect against accidental deletion of objects? / Estás usando un bucket de S3 para almacenar datos críticos. ¿Cuál es la característica más efectiva para proteger contra la eliminación accidental de objetos?", "opciones": ["S3 Cross-Region Replication", "S3 Versioning", "S3 Bucket Policies", "S3 Lifecycle Policies"], "respuesta_correcta": "S3 Versioning", "explicacion": "Versioning keeps multiple variants of an object in the same bucket. When an object is 'deleted', S3 simply adds a delete marker but retains all previous versions. This allows for easy recovery from accidental deletions or overwrites. / El versionado mantiene múltiples variantes de un objeto en el mismo bucket. Cuando un objeto es 'eliminado', S3 simplemente añade un marcador de eliminación pero conserva todas las versiones anteriores. Esto permite una fácil recuperación de eliminaciones o sobrescrituras accidentales." },
        { "area": 3, "pregunta": "What is the primary function of AWS Shield Advanced? / ¿Cuál es la función principal de AWS Shield Advanced?", "opciones": ["To protect against common web exploits like SQL injection and cross-site scripting / Para proteger contra exploits web comunes como inyección SQL y cross-site scripting", "To provide advanced, always-on protection against large and sophisticated DDoS attacks / Para proporcionar protección avanzada y siempre activa contra ataques DDoS grandes y sofisticados", "To scan EC2 instances for vulnerabilities and compliance issues / Para escanear instancias EC2 en busca de vulnerabilidades y problemas de cumplimiento", "To manage and rotate SSL/TLS certificates for your applications / Para gestionar y rotar certificados SSL/TLS para tus aplicaciones"], "respuesta_correcta": "To provide advanced, always-on protection against large and sophisticated DDoS attacks / Para proporcionar protección avanzada y siempre activa contra ataques DDoS grandes y sofisticados", "explicacion": "AWS Shield Standard provides basic DDoS protection for free. Shield Advanced provides enhanced detection, 24/7 access to the AWS DDoS Response Team (DRT), and cost protection against usage spikes during an attack. / AWS Shield Standard proporciona protección DDoS básica de forma gratuita. Shield Advanced ofrece detección mejorada, acceso 24/7 al Equipo de Respuesta a DDoS (DRT) de AWS y protección de costos contra picos de uso durante un ataque." },
        { "area": 3, "pregunta": "An Auto Scaling group is not scaling out during a traffic spike, even though the CPU utilization is very high. What is the MOST likely reason? / Un grupo de Auto Scaling no está escalando horizontalmente durante un pico de tráfico, aunque la utilización de la CPU es muy alta. ¿Cuál es la razón MÁS probable?", "opciones": ["The maximum capacity of the ASG has been reached / Se ha alcanzado la capacidad máxima del ASG", "The health checks are failing for the existing instances / Las comprobaciones de estado están fallando para las instancias existentes", "There is no CloudWatch alarm configured as a scaling policy trigger / No hay una alarma de CloudWatch configurada como disparador de la política de escalado", "The launch template is configured with an incorrect AMI / La plantilla de lanzamiento está configurada con una AMI incorrecta"], "respuesta_correcta": "There is no CloudWatch alarm configured as a scaling policy trigger / No hay una alarma de CloudWatch configurada como disparador de la política de escalado", "explicacion": "Auto Scaling relies on triggers to initiate scaling actions. The most common trigger is a CloudWatch alarm based on a metric like CPUUtilization. Without this alarm and an associated scaling policy, the group will not react to load changes. / Auto Scaling depende de disparadores para iniciar acciones de escalado. El disparador más común es una alarma de CloudWatch basada en una métrica como CPUUtilization. Sin esta alarma y una política de escalado asociada, el grupo no reaccionará a los cambios de carga." },
        { "area": 3, "pregunta": "Which AWS service allows you to test the resilience of your application by deliberately injecting failures and faults into your AWS environment? / ¿Qué servicio de AWS te permite probar la resiliencia de tu aplicación inyectando deliberadamente fallos y errores en tu entorno de AWS?", "opciones": ["AWS Config", "AWS Fault Injection Simulator", "AWS Systems Manager Chaos Conductor", "Amazon Inspector"], "respuesta_correcta": "AWS Fault Injection Simulator", "explicacion": "AWS Fault Injection Simulator (FIS) is a fully managed service for running fault injection experiments on AWS, which is a key practice of chaos engineering to improve application resilience. / AWS Fault Injection Simulator (FIS) es un servicio totalmente gestionado para ejecutar experimentos de inyección de fallos en AWS, lo cual es una práctica clave de la ingeniería del caos para mejorar la resiliencia de las aplicaciones." },
        { "area": 3, "pregunta": "You need to automate the backup of your EBS volumes, EFS file systems, and RDS databases with a centralized service. Which service should you use? / Necesitas automatizar la copia de seguridad de tus volúmenes EBS, sistemas de archivos EFS y bases de datos RDS con un servicio centralizado. ¿Qué servicio deberías usar?", "opciones": ["AWS Data Lifecycle Manager (DLM)", "AWS Backup", "Amazon S3 Lifecycle Policies", "Custom Lambda functions with EventBridge"], "respuesta_correcta": "AWS Backup", "explicacion": "AWS Backup is a centralized backup service that makes it easy to manage backups across multiple AWS services. DLM is primarily for EBS snapshots. / AWS Backup es un servicio de copia de seguridad centralizado que facilita la gestión de copias de seguridad en múltiples servicios de AWS. DLM es principalmente para instantáneas de EBS." },
        { "area": 3, "pregunta": "What is a 'sticky session' (session affinity) in the context of an Application Load Balancer? / ¿Qué es una 'sesión pegajosa' (afinidad de sesión) en el contexto de un Application Load Balancer?", "opciones": ["A security feature that blocks requests from known malicious IP addresses / Una característica de seguridad que bloquea las solicitudes de direcciones IP maliciosas conocidas", "A mechanism that routes all requests from a specific client to the same target instance for the duration of a session / Un mecanismo que enruta todas las solicitudes de un cliente específico a la misma instancia de destino durante la duración de una sesión", "A type of health check that verifies the application session management is working / Un tipo de comprobación de estado que verifica que la gestión de sesiones de la aplicación funciona", "A feature that keeps the backend connection open to reduce latency / Una característica que mantiene abierta la conexión de backend para reducir la latencia"], "respuesta_correcta": "A mechanism that routes all requests from a specific client to the same target instance for the duration of a session / Un mecanismo que enruta todas las solicitudes de un cliente específico a la misma instancia de destino durante la duración de una sesión", "explicacion": "Sticky sessions are useful for stateful applications that store user session information locally on an instance. The ALB uses a cookie to ensure that subsequent requests from the same user are sent to the same instance. / Las sesiones pegajosas son útiles para aplicaciones con estado que almacenan información de la sesión del usuario localmente en una instancia. El ALB usa una cookie para asegurar que las solicitudes posteriores del mismo usuario se envíen a la misma instancia." },
        { "area": 3, "pregunta": "For a global application, you want to route users to the AWS region that provides the lowest network latency. Which Route 53 routing policy is most suitable? / Para una aplicación global, quieres enrutar a los usuarios a la región de AWS que proporciona la latencia de red más baja. ¿Qué política de enrutamiento de Route 53 es más adecuada?", "opciones": ["Geolocation Routing", "Geoproximity Routing", "Failover Routing", "Latency-based Routing"], "respuesta_correcta": "Latency-based Routing", "explicacion": "Latency-based routing uses latency measurements between users and AWS data centers to route users to the region that will give them the fastest response time. Geolocation routes based on the user's geographic location, not latency. / El enrutamiento basado en latencia utiliza mediciones de latencia entre los usuarios y los centros de datos de AWS para enrutar a los usuarios a la región que les dará el tiempo de respuesta más rápido. El enrutamiento por geolocalización se basa en la ubicación geográfica del usuario, no en la latencia." },
        { "area": 3, "pregunta": "What is the function of a 'lifecycle hook' in an Auto Scaling group? / ¿Cuál es la función de un 'gancho de ciclo de vida' en un grupo de Auto Scaling?", "opciones": ["To run a script on an instance before it is terminated by the ASG / Para ejecutar un script en una instancia antes de que sea terminada por el ASG", "To attach a specific ENI to an instance when it is launched / Para adjuntar una ENI específica a una instancia cuando se lanza", "To define the health check criteria for an instance / Para definir los criterios de comprobación de estado para una instancia", "To trigger a scaling action based on a custom metric / Para disparar una acción de escalado basada en una métrica personalizada"], "respuesta_correcta": "To run a script on an instance before it is terminated by the ASG / Para ejecutar un script en una instancia antes de que sea terminada por el ASG", "explicacion": "Lifecycle hooks allow you to pause the instance launch or termination process to perform custom actions, such as downloading log files or draining connections before an instance is terminated during a scale-in event. / Los ganchos de ciclo de vida te permiten pausar el proceso de lanzamiento o terminación de la instancia para realizar acciones personalizadas, como descargar archivos de registro o drenar conexiones antes de que una instancia se termine durante un evento de reducción de escala." },
        { "area": 3, "pregunta": "To serve web content with low latency to a global audience, you should place your static assets in S3 and front it with which service? / Para servir contenido web con baja latencia a una audiencia global, deberías colocar tus activos estáticos en S3 y poner al frente qué servicio?", "opciones": ["Application Load Balancer", "AWS Global Accelerator", "Amazon CloudFront", "Route 53"], "respuesta_correcta": "Amazon CloudFront", "explicacion": "CloudFront is AWS's Content Delivery Network (CDN). It caches copies of your content in edge locations around the world, significantly reducing latency for users by serving content from a location geographically closer to them. / CloudFront es la Red de Entrega de Contenido (CDN) de AWS. Almacena en caché copias de tu contenido en ubicaciones de borde de todo el mundo, reduciendo significativamente la latencia para los usuarios al servir el contenido desde una ubicación geográficamente más cercana a ellos." },
        { "area": 3, "pregunta": "What does 'RPO' (Recovery Point Objective) define in a disaster recovery plan? / ¿Qué define el 'RPO' (Objetivo de Punto de Recuperación) en un plan de recuperación de desastres?", "opciones": ["The maximum acceptable amount of time to restore a service after a disaster / La cantidad máxima de tiempo aceptable para restaurar un servicio después de un desastre", "The maximum acceptable amount of data loss, measured in time / La cantidad máxima de pérdida de datos aceptable, medida en tiempo", "The percentage of service functionality that must be available after a disaster / El porcentaje de funcionalidad del servicio que debe estar disponible después de un desastre", "The geographical distance required between the primary and recovery sites / La distancia geográfica requerida entre los sitios primario y de recuperación"], "respuesta_correcta": "The maximum acceptable amount of data loss, measured in time / La cantidad máxima de pérdida de datos aceptable, medida en tiempo", "explicacion": "RPO is about data loss. An RPO of 1 hour means the business can tolerate losing up to 1 hour of data in a disaster. RTO (Recovery Time Objective) is the time it takes to recover the service. / El RPO se refiere a la pérdida de datos. Un RPO de 1 hora significa que el negocio puede tolerar la pérdida de hasta 1 hora de datos en un desastre. El RTO (Objetivo de Tiempo de Recuperación) es el tiempo que se tarda en recuperar el servicio." },
        { "area": 3, "pregunta": "How can AWS Global Accelerator improve application availability? / ¿Cómo puede AWS Global Accelerator mejorar la disponibilidad de la aplicación?", "opciones": ["By caching static content at edge locations / Almacenando en caché contenido estático en ubicaciones de borde", "By providing static IP addresses that act as a fixed entry point and re-routing traffic to healthy endpoints across regions / Proporcionando direcciones IP estáticas que actúan como un punto de entrada fijo y re-enrutando el tráfico a endpoints saludables entre regiones", "By automatically scaling the number of EC2 instances based on traffic / Escalando automáticamente el número de instancias EC2 según el tráfico", "By encrypting data in transit between the client and the application / Cifrando los datos en tránsito entre el cliente y la aplicación"], "respuesta_correcta": "By providing static IP addresses that act as a fixed entry point and re-routing traffic to healthy endpoints across regions / Proporcionando direcciones IP estáticas que actúan como un punto de entrada fijo y re-enrutando el tráfico a endpoints saludables entre regiones", "explicacion": "Global Accelerator uses the AWS global network to route traffic to the optimal regional endpoint. It provides two static IPs, and if an endpoint fails, it instantly re-routes traffic to the next best endpoint without requiring any client-side changes. / Global Accelerator utiliza la red global de AWS para enrutar el tráfico al endpoint regional óptimo. Proporciona dos IPs estáticas, y si un endpoint falla, re-enruta instantáneamente el tráfico al siguiente mejor endpoint sin requerir ningún cambio del lado del cliente." },
        { "area": 3, "pregunta": "Your RDS database is a performance bottleneck due to a high volume of read queries. How can you improve performance without changing the primary instance size? / Tu base de datos RDS es un cuello de botella de rendimiento debido a un alto volumen de consultas de lectura. ¿Cómo puedes mejorar el rendimiento sin cambiar el tamaño de la instancia principal?", "opciones": ["Enable Multi-AZ deployment / Habilitar el despliegue Multi-AZ", "Create one or more Read Replicas and direct read traffic to them / Crear una o más Réplicas de Lectura y dirigir el tráfico de lectura hacia ellas", "Increase the Provisioned IOPS of the EBS volume / Aumentar las IOPS Provisionadas del volumen EBS", "Use Amazon ElastiCache to cache database queries / Usar Amazon ElastiCache para almacenar en caché las consultas de la base de datos"], "respuesta_correcta": "Create one or more Read Replicas and direct read traffic to them / Crear una o más Réplicas de Lectura y dirigir el tráfico de lectura hacia ellas", "explicacion": "Read Replicas are designed to offload read traffic from the primary database instance. They use asynchronous replication and are a primary strategy for scaling read-heavy database workloads. / Las Réplicas de Lectura están diseñadas para descargar el tráfico de lectura de la instancia de base de datos principal. Usan replicación asíncrona y son una estrategia principal para escalar cargas de trabajo de base de datos con muchas lecturas." },
        { "area": 3, "pregunta": "What is the 'pilot light' disaster recovery strategy? / ¿En qué consiste la estrategia de recuperación de desastres 'luz piloto'?", "opciones": ["A fully scaled-down version of the environment is running in the DR region / Una versión completamente a escala reducida del entorno está funcionando en la región de DR", "Only the core data is replicated to the DR region; infrastructure must be provisioned during a disaster / Solo los datos principales se replican en la región de DR; la infraestructura debe aprovisionarse durante un desastre", "A complete, full-scale duplicate of the production environment is running in the DR region / Un duplicado completo y a escala real del entorno de producción está funcionando en la región de DR", "Backups are sent to the DR region, but no infrastructure is pre-provisioned / Las copias de seguridad se envían a la región de DR, pero no hay infraestructura pre-aprovisionada"], "respuesta_correcta": "Only the core data is replicated to the DR region; infrastructure must be provisioned during a disaster / Solo los datos principales se replican en la región de DR; la infraestructura debe aprovisionarse durante un desastre", "explicacion": "In a pilot light strategy, the most critical core elements are kept running at a minimal level (like the database). The application infrastructure is defined in IaC but is only fully provisioned and scaled up during a failover event. / En una estrategia de luz piloto, los elementos centrales más críticos se mantienen funcionando a un nivel mínimo (como la base de datos). La infraestructura de la aplicación se define en IaC pero solo se aprovisiona y escala por completo durante un evento de conmutación por error." },
        { "area": 3, "pregunta": "Which feature of an Application Load Balancer allows you to route traffic to different target groups based on the URL path or hostname? / ¿Qué característica de un Application Load Balancer te permite enrutar el tráfico a diferentes grupos de destino según la ruta de la URL o el nombre de host?", "opciones": ["Cross-Zone Load Balancing", "Path-based and Host-based Routing", "Sticky Sessions", "Connection Draining"], "respuesta_correcta": "Path-based and Host-based Routing", "explicacion": "ALBs operate at Layer 7 and can inspect the request. Listener rules can be configured to forward requests to different backend services based on the path (e.g., /api vs /images) or the hostname (e.g., api.example.com vs. www.example.com). / Los ALBs operan en la Capa 7 y pueden inspeccionar la solicitud. Las reglas del listener se pueden configurar para reenviar solicitudes a diferentes servicios de backend según la ruta (ej: /api vs /images) o el nombre de host (ej: api.example.com vs. www.example.com)." }
    ],
    "area4": [
        { "area": 4, "pregunta": "You need to create a CloudWatch Alarm that triggers only if two separate metrics breach their thresholds simultaneously (e.g., high CPU and low network traffic). How should you implement this? / Necesitas crear una Alarma de CloudWatch que se active solo si dos métricas distintas superan sus umbrales simultáneamente (ej: CPU alta y tráfico de red bajo). ¿Cómo deberías implementarlo?", "opciones": ["Create a single alarm with two metric conditions / Crear una sola alarma con dos condiciones de métrica", "Create a Composite Alarm that monitors two separate base alarms / Crear una Alarma Compuesta que monitoree dos alarmas base separadas", "Use a Metric Math expression with an IF statement / Usar una expresión de Metric Math con una declaración IF", "Trigger a Lambda function from the first alarm to check the second metric / Disparar una función Lambda desde la primera alarma para comprobar la segunda métrica"], "respuesta_correcta": "Create a Composite Alarm that monitors two separate base alarms / Crear una Alarma Compuesta que monitoree dos alarmas base separadas", "explicacion": "Composite Alarms are designed for this exact scenario. They allow you to create complex alarm logic by combining the states of multiple other alarms using AND/OR operators. / Las Alarmas Compuestas están diseñadas para este escenario exacto. Te permiten crear lógica de alarma compleja combinando los estados de múltiples otras alarmas usando operadores Y/O." },
        { "area": 4, "pregunta": "Application logs are being sent to a CloudWatch Logs log group. You need to get near-real-time notifications via email whenever an 'ERROR' pattern appears in the logs. What is the most direct way to achieve this? / Los logs de una aplicación se envían a un grupo de logs de CloudWatch. Necesitas recibir notificaciones casi en tiempo real por correo electrónico cada vez que aparece un patrón 'ERROR' en los logs. ¿Cuál es la forma más directa de lograrlo?", "opciones": ["Create a Lambda function to periodically scan the log group / Crear una función Lambda para escanear periódicamente el grupo de logs", "Create a metric filter on the log group and an alarm on the resulting metric that notifies an SNS topic / Crear un filtro de métrica en el grupo de logs y una alarma sobre la métrica resultante que notifique a un tema de SNS", "Use CloudWatch Logs Insights to query for errors and export the results / Usar CloudWatch Logs Insights para consultar errores y exportar los resultados", "Stream the logs to Amazon S3 and use S3 Event Notifications / Transmitir los logs a Amazon S3 y usar Notificaciones de Eventos de S3"], "respuesta_correcta": "Create a metric filter on the log group and an alarm on the resulting metric that notifies an SNS topic / Crear un filtro de métrica en el grupo de logs y una alarma sobre la métrica resultante que notifique a un tema de SNS", "explicacion": "Metric filters allow you to turn log data into numerical CloudWatch metrics. You can create a filter for the 'ERROR' pattern, which generates a metric. Then, an alarm can monitor this metric and trigger an SNS notification when it increments. / Los filtros de métrica te permiten convertir datos de logs en métricas numéricas de CloudWatch. Puedes crear un filtro para el patrón 'ERROR', que genera una métrica. Luego, una alarma puede monitorear esta métrica y disparar una notificación de SNS cuando se incrementa." },
        { "area": 4, "pregunta": "What is the primary purpose of AWS X-Ray in a microservices architecture? / ¿Cuál es el propósito principal de AWS X-Ray en una arquitectura de microservicios?", "opciones": ["To aggregate and search application logs / Para agregar y buscar en los logs de la aplicación", "To trace and analyze requests as they travel through your application, identifying bottlenecks and performance issues / Para rastrear y analizar las solicitudes a medida que viajan a través de tu aplicación, identificando cuellos de botella y problemas de rendimiento", "To monitor the health of individual EC2 instances / Para monitorear la salud de instancias EC2 individuales", "To automate the deployment of services / Para automatizar el despliegue de servicios"], "respuesta_correcta": "To trace and analyze requests as they travel through your application, identifying bottlenecks and performance issues / Para rastrear y analizar las solicitudes a medida que viajan a través de tu aplicación, identificando cuellos de botella y problemas de rendimiento", "explicacion": "X-Ray is a distributed tracing service. It helps developers analyze and debug production, distributed applications, such as those built using a microservices architecture, by providing a visual service map and trace details. / X-Ray es un servicio de trazado distribuido. Ayuda a los desarrolladores a analizar y depurar aplicaciones de producción distribuidas, como las construidas con una arquitectura de microservicios, proporcionando un mapa de servicio visual y detalles de la traza." },
        { "area": 4, "pregunta": "You want to create a CloudWatch Dashboard that shows a single graph of the average CPU utilization across all instances in an Auto Scaling group. How can you achieve this? / Quieres crear un Dashboard de CloudWatch que muestre un único gráfico del promedio de utilización de CPU de todas las instancias en un grupo de Auto Scaling. ¿Cómo puedes lograrlo?", "opciones": ["Create a separate graph for each instance and place them together / Crear un gráfico separado para cada instancia y colocarlos juntos", "Graph the `CPUUtilization` metric and specify the `AutoScalingGroupName` dimension / Graficar la métrica `CPUUtilization` y especificar la dimensión `AutoScalingGroupName`", "Use a Metric Math expression to average the metrics from all instances / Usar una expresión de Metric Math para promediar las métricas de todas las instancias", "This is not possible; you must view metrics per instance / Esto no es posible; debes ver las métricas por instancia"], "respuesta_correcta": "Graph the `CPUUtilization` metric and specify the `AutoScalingGroupName` dimension / Graficar la métrica `CPUUtilization` y especificar la dimensión `AutoScalingGroupName`", "explicacion": "EC2 metrics are published with an `AutoScalingGroupName` dimension. By selecting the metric and only this dimension (leaving the `InstanceId` dimension empty), CloudWatch automatically aggregates the metric (e.g., as an average) across all instances in that group into a single line on the graph. / Las métricas de EC2 se publican con una dimensión `AutoScalingGroupName`. Al seleccionar la métrica y solo esta dimensión (dejando la dimensión `InstanceId` vacía), CloudWatch agrega automáticamente la métrica (por ejemplo, como un promedio) de todas las instancias de ese grupo en una sola línea en el gráfico." },
        { "area": 4, "pregunta": "Which CloudTrail log type provides a record of all API calls made to your AWS account, including those from the console, SDKs, and CLI? / ¿Qué tipo de registro de CloudTrail proporciona un registro de todas las llamadas a la API realizadas a tu cuenta de AWS, incluidas las de la consola, los SDK y la CLI?", "opciones": ["Data Events", "Management Events", "Insights Events", "Global Service Events"], "respuesta_correcta": "Management Events", "explicacion": "Management events (also known as 'control plane operations') provide insight into management operations performed on resources in your AWS account. They are the most common type of audited event and are enabled by default on a trail. / Los eventos de gestión (también conocidos como 'operaciones del plano de control') proporcionan información sobre las operaciones de gestión realizadas en los recursos de tu cuenta de AWS. Son el tipo más común de evento auditado y están habilitados por defecto en un trail." },
        { "area": 4, "pregunta": "You have enabled AWS X-Ray tracing for your application. What must be included in requests between your services for X-Ray to correlate them into a single trace? / Has habilitado el trazado de AWS X-Ray para tu aplicación. ¿Qué debe incluirse en las solicitudes entre tus servicios para que X-Ray pueda correlacionarlas en una sola traza?", "opciones": ["An IAM role ARN / El ARN de un rol de IAM", "A trace header (e.g., `X-Amzn-Trace-Id`) / Una cabecera de traza (ej: `X-Amzn-Trace-Id`)", "A VPC endpoint ID / Un ID de endpoint de VPC", "A custom CloudWatch metric / Una métrica de CloudWatch personalizada"], "respuesta_correcta": "A trace header (e.g., `X-Amzn-Trace-Id`) / Una cabecera de traza (ej: `X-Amzn-Trace-Id`)", "explicacion": "The X-Ray SDK automatically adds a tracing header to downstream HTTP requests. This header contains the trace ID, parent segment ID, and sampling decision, which allows the X-Ray service to link all segments together. / El SDK de X-Ray añade automáticamente una cabecera de trazado a las solicitudes HTTP posteriores. Esta cabecera contiene el ID de la traza, el ID del segmento padre y la decisión de muestreo, lo que permite al servicio X-Ray vincular todos los segmentos." },
        { "area": 4, "pregunta": "You need to retain VPC Flow Logs for 5 years for compliance reasons. What is the most cost-effective storage solution for this long-term retention? / Necesitas retener los VPC Flow Logs durante 5 años por motivos de cumplimiento. ¿Cuál es la solución de almacenamiento más rentable para esta retención a largo plazo?", "opciones": ["Publish logs to CloudWatch Logs with a 5-year retention period / Publicar los logs en CloudWatch Logs con un período de retención de 5 años", "Publish logs to an S3 bucket and use the S3 Glacier Deep Archive storage class / Publicar los logs en un bucket de S3 y usar la clase de almacenamiento S3 Glacier Deep Archive", "Stream logs to Amazon OpenSearch Service / Transmitir los logs al servicio Amazon OpenSearch", "Store logs in a DynamoDB table / Almacenar los logs en una tabla de DynamoDB"], "respuesta_correcta": "Publish logs to an S3 bucket and use the S3 Glacier Deep Archive storage class / Publicar los logs en un bucket de S3 y usar la clase de almacenamiento S3 Glacier Deep Archive", "explicacion": "S3 is the most cost-effective destination for long-term log archival. By using a lifecycle policy to transition logs to the S3 Glacier Deep Archive storage class, you can achieve the lowest storage cost for data that is rarely accessed. / S3 es el destino más rentable para el archivo de logs a largo plazo. Al usar una política de ciclo de vida para transferir los logs a la clase de almacenamiento S3 Glacier Deep Archive, puedes lograr el costo de almacenamiento más bajo para datos a los que se accede raramente." },
        { "area": 4, "pregunta": "What is a key difference between a CloudWatch basic resolution metric and a high-resolution metric? / ¿Cuál es una diferencia clave entre una métrica de resolución básica de CloudWatch y una métrica de alta resolución?", "opciones": ["High-resolution metrics can be published every 1 second, while basic resolution is every 1 minute / Las métricas de alta resolución se pueden publicar cada 1 segundo, mientras que la resolución básica es cada 1 minuto", "High-resolution metrics cost more to store than basic resolution metrics / Las métricas de alta resolución cuestan más de almacenar que las de resolución básica", "You can only set alarms on high-resolution metrics / Solo puedes establecer alarmas en métricas de alta resolución", "Only custom metrics can be high-resolution / Solo las métricas personalizadas pueden ser de alta resolución"], "respuesta_correcta": "High-resolution metrics can be published every 1 second, while basic resolution is every 1 minute / Las métricas de alta resolución se pueden publicar cada 1 segundo, mientras que la resolución básica es cada 1 minuto", "explicacion": "High-resolution allows you to publish custom metrics at a 1, 5, 10, or 30-second interval, providing more immediate insight into your application's sub-minute performance. Standard resolution is 60 seconds (1 minute). / La alta resolución te permite publicar métricas personalizadas en un intervalo de 1, 5, 10 o 30 segundos, proporcionando una visión más inmediata del rendimiento de tu aplicación en menos de un minuto. La resolución estándar es de 60 segundos (1 minuto)." },
        { "area": 4, "pregunta": "You want to be notified if any user in your AWS account attempts to delete an S3 bucket. Which service combination should you use? / Quieres ser notificado si algún usuario en tu cuenta de AWS intenta eliminar un bucket de S3. ¿Qué combinación de servicios deberías usar?", "opciones": ["CloudWatch Logs metric filter and an SNS alarm / Filtro de métrica de CloudWatch Logs y una alarma de SNS", "EventBridge rule with a CloudTrail `DeleteBucket` event pattern and an SNS target / Regla de EventBridge con un patrón de evento de CloudTrail `DeleteBucket` y un destino de SNS", "AWS Config rule and an SSM Automation document / Regla de AWS Config y un documento de SSM Automation", "AWS Shield and a WAF rule / AWS Shield y una regla de WAF"], "respuesta_correcta": "EventBridge rule with a CloudTrail `DeleteBucket` event pattern and an SNS target / Regla de EventBridge con un patrón de evento de CloudTrail `DeleteBucket` y un destino de SNS", "explicacion": "CloudTrail logs the `DeleteBucket` API call. EventBridge can create a rule that specifically matches this event and then trigger a target, such as an SNS topic, to send a notification. This is the most direct and event-driven approach. / CloudTrail registra la llamada a la API `DeleteBucket`. EventBridge puede crear una regla que coincida específicamente con este evento y luego activar un destino, como un tema de SNS, para enviar una notificación. Este es el enfoque más directo y basado en eventos." },
        { "area": 4, "pregunta": "What is the purpose of a 'Subscription Filter' in CloudWatch Logs? / ¿Cuál es el propósito de un 'Filtro de Suscripción' en CloudWatch Logs?", "opciones": ["To convert log data into CloudWatch metrics / Para convertir datos de logs en métricas de CloudWatch", "To provide real-time streaming of log events to other services like Lambda, Kinesis, or OpenSearch / Para proporcionar transmisión en tiempo real de eventos de log a otros servicios como Lambda, Kinesis u OpenSearch", "To define the retention period for a log group / Para definir el período de retención para un grupo de logs", "To search and analyze log data using a query language / Para buscar y analizar datos de logs usando un lenguaje de consulta"], "respuesta_correcta": "To provide real-time streaming of log events to other services like Lambda, Kinesis, or OpenSearch / Para proporcionar transmisión en tiempo real de eventos de log a otros servicios como Lambda, Kinesis u OpenSearch", "explicacion": "Subscription filters allow you to deliver a real-time feed of ingested log events that match a specific pattern to another service for custom processing, analysis, or loading into other systems. / Los filtros de suscripción te permiten entregar una fuente en tiempo real de eventos de log ingeridos que coinciden con un patrón específico a otro servicio para procesamiento personalizado, análisis o carga en otros sistemas." },
        { "area": 4, "pregunta": "You are trying to diagnose a latency issue in your serverless application. AWS X-Ray shows a large time gap between a Lambda function and a downstream DynamoDB call. What does this gap likely represent? / Estás intentando diagnosticar un problema de latencia en tu aplicación sin servidor. AWS X-Ray muestra una gran brecha de tiempo entre una función Lambda y una llamada posterior a DynamoDB. ¿Qué representa probablemente esta brecha?", "opciones": ["The time the request was queued in the Lambda service / El tiempo que la solicitud estuvo en cola en el servicio Lambda", "The time spent in the DynamoDB service processing the request / El tiempo que el servicio DynamoDB tardó en procesar la solicitud", "The time spent within your Lambda function's code executing logic before making the DynamoDB call / El tiempo que tu código de la función Lambda tardó en ejecutar la lógica antes de hacer la llamada a DynamoDB", "A network connectivity issue between Lambda and DynamoDB / Un problema de conectividad de red entre Lambda y DynamoDB"], "respuesta_correcta": "The time spent within your Lambda function's code executing logic before making the DynamoDB call / El tiempo que tu código de la función Lambda tardó en ejecutar la lógica antes de hacer la llamada a DynamoDB", "explicacion": "X-Ray segments represent calls to services. A time gap between two segments in a trace indicates time spent in the code of the parent service (the Lambda function in this case) that is not part of a downstream call. / Los segmentos de X-Ray representan llamadas a servicios. Una brecha de tiempo entre dos segmentos en una traza indica el tiempo que se pasó en el código del servicio padre (la función Lambda en este caso) que no forma parte de una llamada posterior." },
        { "area": 4, "pregunta": "How can you collect detailed memory utilization metrics from your EC2 instances in CloudWatch? / ¿Cómo puedes recopilar métricas detalladas de utilización de memoria de tus instancias EC2 en CloudWatch?", "opciones": ["Enable detailed monitoring for the EC2 instances / Habilitar la monitorización detallada para las instancias EC2", "This metric is collected by default by CloudWatch / Esta métrica es recopilada por defecto por CloudWatch", "Install the CloudWatch agent on the instances and configure it to collect memory metrics / Instalar el agente de CloudWatch en las instancias y configurarlo para que recopile métricas de memoria", "Create a custom script that uses the EC2 metadata service / Crear un script personalizado que use el servicio de metadatos de EC2"], "respuesta_correcta": "Install the CloudWatch agent on the instances and configure it to collect memory metrics / Instalar el agente de CloudWatch en las instancias y configurarlo para que recopile métricas de memoria", "explicacion": "By default, EC2 metrics sent to CloudWatch do not include memory or disk space utilization. You must install the unified CloudWatch agent on the instance to collect these as custom metrics. / Por defecto, las métricas de EC2 enviadas a CloudWatch no incluyen la utilización de memoria o espacio en disco. Debes instalar el agente unificado de CloudWatch en la instancia para recopilar estas como métricas personalizadas." },
        { "area": 4, "pregunta": "An alarm is 'flapping' (repeatedly transitioning between OK, ALARM, and INSUFFICIENT_DATA). What is a common cause for this? / una alarma está 'flapeando' (transicionando repetidamente entre OK, ALARMA e INSUFFICIENT_DATA). ¿Cuál es una causa común de esto?", "opciones": ["The metric is published intermittently or has a low frequency / La métrica se publica de forma intermitente o tiene una frecuencia baja", "The alarm threshold is set too high / El umbral de la alarma está configurado demasiado alto", "The SNS topic for the alarm is misconfigured / El tema de SNS para la alarma está mal configurado", "The alarm's evaluation period is too long / El período de evaluación de la alarma es demasiado largo"], "respuesta_correcta": "The metric is published intermittently or has a low frequency / La métrica se publica de forma intermitente o tiene una frecuencia baja", "explicacion": "If a metric doesn't publish data for every evaluation period, the alarm state can change to INSUFFICIENT_DATA. When a new data point arrives, it might go back to OK or ALARM, causing flapping. This is common for event-driven metrics. / Si una métrica no publica datos para cada período de evaluación, el estado de la alarma puede cambiar a INSUFFICIENT_DATA. Cuando llega un nuevo punto de datos, puede volver a OK o ALARMA, causando el 'flapeo'. Esto es común para métricas basadas en eventos." },
        { "area": 4, "pregunta": "What is the purpose of CloudTrail Insights? / ¿Cuál es el propósito de CloudTrail Insights?", "opciones": ["To provide a visual dashboard of CloudTrail events / Para proporcionar un panel visual de los eventos de CloudTrail", "To automatically detect unusual or anomalous API activity in your AWS account / Para detectar automáticamente actividad de API inusual o anómala en tu cuenta de AWS", "To query and analyze CloudTrail logs using SQL / Para consultar y analizar los logs de CloudTrail usando SQL", "To encrypt CloudTrail logs for long-term storage / Para cifrar los logs de CloudTrail para almacenamiento a largo plazo"], "respuesta_correcta": "To automatically detect unusual or anomalous API activity in your AWS account / Para detectar automáticamente actividad de API inusual o anómala en tu cuenta de AWS", "explicacion": "CloudTrail Insights uses machine learning to analyze your management events and automatically detects unusual patterns, such as spikes in resource provisioning or gaps in periodic maintenance activity, which could indicate a security threat or operational issue. / CloudTrail Insights utiliza el aprendizaje automático para analizar tus eventos de gestión y detecta automáticamente patrones inusuales, como picos en el aprovisionamiento de recursos o brechas en la actividad de mantenimiento periódico, lo que podría indicar una amenaza de seguridad o un problema operativo." },
        { "area": 4, "pregunta": "You want to create a single graph that shows the result of a calculation, such as the error rate (5xx errors / total requests) for an Application Load Balancer. Which CloudWatch feature should you use? / Quieres crear un único gráfico que muestre el resultado de un cálculo, como la tasa de errores (errores 5xx / solicitudes totales) para un Application Load Balancer. ¿Qué característica de CloudWatch deberías usar?", "opciones": ["Composite Alarms", "Metric Filters", "Metric Math", "CloudWatch Anomaly Detection"], "respuesta_correcta": "Metric Math", "explicacion": "Metric Math allows you to perform calculations across multiple CloudWatch metrics. You can create a new time-series metric based on a mathematical expression of other metrics, which is perfect for calculating rates and ratios. / Metric Math te permite realizar cálculos entre múltiples métricas de CloudWatch. Puedes crear una nueva métrica de serie temporal basada en una expresión matemática de otras métricas, lo cual es perfecto para calcular tasas y proporciones." },
        { "area": 4, "pregunta": "How can you ensure that CloudTrail log files stored in S3 have not been tampered with? / ¿Cómo puedes asegurar que los archivos de log de CloudTrail almacenados en S3 no han sido manipulados?", "opciones": ["Enable S3 Versioning on the bucket / Habilitar el Versionado de S3 en el bucket", "Enable CloudTrail log file validation / Habilitar la validación de archivos de log de CloudTrail", "Encrypt the log files using SSE-KMS / Cifrar los archivos de log usando SSE-KMS", "Restrict access to the bucket using an S3 bucket policy / Restringir el acceso al bucket usando una política de bucket de S3"], "respuesta_correcta": "Enable CloudTrail log file validation / Habilitar la validación de archivos de log de CloudTrail", "explicacion": "When you enable log file validation, CloudTrail creates a digitally signed digest file containing a hash of the log file. You can use these digest files to verify that the log file was not altered after CloudTrail delivered it. / Cuando habilitas la validación de archivos de log, CloudTrail crea un archivo de resumen firmado digitalmente que contiene un hash del archivo de log. Puedes usar estos archivos de resumen para verificar que el archivo de log no fue alterado después de que CloudTrail lo entregó." },
        { "area": 4, "pregunta": "You need to search and analyze logs from multiple sources, including VPC Flow Logs, application logs, and Route 53 logs, using a powerful query language. Which service is best suited for this task? / Necesitas buscar y analizar logs de múltiples fuentes, incluyendo VPC Flow Logs, logs de aplicaciones y logs de Route 53, usando un lenguaje de consulta potente. ¿Qué servicio es el más adecuado para esta tarea?", "opciones": ["CloudWatch Dashboards", "CloudWatch Logs Insights", "AWS X-Ray Analytics", "CloudTrail"], "respuesta_correcta": "CloudWatch Logs Insights", "explicacion": "CloudWatch Logs Insights is a purpose-built query and analysis tool for log data in CloudWatch Logs. It provides a sophisticated query language to search, aggregate, and visualize logs from many different sources interactively. / CloudWatch Logs Insights es una herramienta de consulta y análisis especialmente diseñada para los datos de logs en CloudWatch Logs. Proporciona un lenguaje de consulta sofisticado para buscar, agregar y visualizar logs de muchas fuentes diferentes de forma interactiva." },
        { "area": 4, "pregunta": "What is an X-Ray 'annotation'? / ¿Qué es una 'anotación' de X-Ray?", "opciones": ["A key-value pair added to a trace segment used for filtering traces / Un par clave-valor añadido a un segmento de traza que se utiliza para filtrar trazas", "Detailed debugging information that is not indexed for searching / Información de depuración detallada que no está indexada para la búsqueda", "An automatic flag added by X-Ray when it detects an error / Una bandera automática añadida por X-Ray cuando detecta un error", "A link between two different traces / Un enlace entre dos trazas diferentes"], "respuesta_correcta": "A key-value pair added to a trace segment used for filtering traces / Un par clave-valor añadido a un segmento de traza que se utiliza para filtrar trazas", "explicacion": "Annotations are simple key-value pairs that are indexed for use in filter expressions. For example, you can add an annotation for `userId` or `orderId` to a trace and then use the X-Ray console to find all traces for that specific user or order. Metadata is for data you don't need to search on. / Las anotaciones son pares clave-valor simples que se indexan para su uso en expresiones de filtro. Por ejemplo, puedes añadir una anotación para `userId` o `orderId` a una traza y luego usar la consola de X-Ray para encontrar todas las trazas de ese usuario u pedido específico. Los metadatos son para datos sobre los que no necesitas buscar." },
        { "area": 4, "pregunta": "Which EventBridge feature allows you to archive events and replay them at a later time, for example, to test new event consumers? / ¿Qué característica de EventBridge te permite archivar eventos y reproducirlos en un momento posterior, por ejemplo, para probar nuevos consumidores de eventos?", "opciones": ["Event Buses", "Event Replay", "Schema Registry", "API Destinations"], "respuesta_correcta": "Event Replay", "explicacion": "Event Replay is a feature that enables you to reprocess past events from an archive. This is useful for debugging, hydrating new applications with historical data, or testing new features against real-world event patterns. / La Reproducción de Eventos es una característica que te permite reprocesar eventos pasados desde un archivo. Esto es útil para depurar, hidratar nuevas aplicaciones con datos históricos o probar nuevas características contra patrones de eventos del mundo real." },
        { "area": 4, "pregunta": "A CloudWatch alarm is configured with a period of 5 minutes and an evaluation period of 3. What does this mean? / Una alarma de CloudWatch está configurada con un período de 5 minutos y un período de evaluación de 3. ¿Qué significa esto?", "opciones": ["The alarm will trigger if the metric breaches the threshold for 15 consecutive minutes / La alarma se activará si la métrica supera el umbral durante 15 minutos consecutivos", "The alarm will evaluate the metric every 15 minutes / La alarma evaluará la métrica cada 15 minutos", "The alarm will trigger if 3 out of the last 3 five-minute data points are breaching the threshold / La alarma se activará si 3 de los últimos 3 puntos de datos de cinco minutos superan el umbral", "The alarm will trigger after 3 breaches, with a 5-minute cool-down period / La alarma se activará después de 3 infracciones, con un período de enfriamiento de 5 minutos"], "respuesta_correcta": "The alarm will trigger if 3 out of the last 3 five-minute data points are breaching the threshold / La alarma se activará si 3 de los últimos 3 puntos de datos de cinco minutos superan el umbral", "explicacion": "The 'Period' is the length of time over which the metric is aggregated. The 'Evaluation Periods' is the number of most recent consecutive periods to check. So, this alarm checks the last three 5-minute periods and goes into ALARM state if all three were breaching. / El 'Período' es el lapso de tiempo durante el cual se agrega la métrica. Los 'Períodos de Evaluación' es el número de períodos consecutivos más recientes a comprobar. Por lo tanto, esta alarma comprueba los últimos tres períodos de 5 minutos y entra en estado de ALARMA si los tres estaban infringiendo." }
    ],
    "area5": [
        { "area": 5, "pregunta": "An AWS Config rule detects a non-compliant resource. You want to automatically trigger a remediation action using an SSM Automation document. What is the most direct way to orchestrate this? / una regla de AWS Config detecta un recurso no conforme. Quieres disparar automáticamente una acción de remediación usando un documento de SSM Automation. ¿Cuál es la forma más directa de orquestar esto?", "opciones": ["Configure the AWS Config rule to send a notification to an SNS topic that a Lambda function subscribes to / Configurar la regla de AWS Config para enviar una notificación a un tema de SNS al que se suscribe una función Lambda", "Create an EventBridge rule that listens for Config compliance change events and sets the SSM document as the target / Crear una regla de EventBridge que escuche los eventos de cambio de conformidad de Config y establezca el documento de SSM como el destino", "Configure the remediation action directly within the AWS Config rule settings / Configurar la acción de remediación directamente en la configuración de la regla de AWS Config", "Create a CloudWatch Alarm based on the Config rule's metrics / Crear una Alarma de CloudWatch basada en las métricas de la regla de Config"], "respuesta_correcta": "Configure the remediation action directly within the AWS Config rule settings / Configurar la acción de remediación directamente en la configuración de la regla de AWS Config", "explicacion": "AWS Config has a built-in feature for automatic remediation. You can directly associate an SSM Automation document with a Config rule to be executed when a resource is found to be non-compliant. / AWS Config tiene una función incorporada para la remediación automática. Puedes asociar directamente un documento de SSM Automation con una regla de Config para que se ejecute cuando se detecte que un recurso no es conforme." },
        { "area": 5, "pregunta": "A security incident is underway, and you need to quickly isolate a compromised EC2 instance from the network to prevent lateral movement, while still allowing forensic analysis. What is the most effective first step? / Un incidente de seguridad está en curso y necesitas aislar rápidamente una instancia EC2 comprometida de la red para evitar movimientos laterales, pero permitiendo el análisis forense. ¿Cuál es el primer paso más efectivo?", "opciones": ["Terminate the instance immediately to remove the threat / Terminar la instancia inmediatamente para eliminar la amenaza", "Change the instance's security group to one that denies all inbound and outbound traffic except from a trusted forensic IP / Cambiar el grupo de seguridad de la instancia a uno que deniegue todo el tráfico entrante y saliente, excepto desde una IP forense de confianza", "Detach the ENI from the instance / Desvincular la ENI de la instancia", "Take an EBS snapshot of the root volume and then terminate the instance / Tomar una instantánea EBS del volumen raíz y luego terminar la instancia"], "respuesta_correcta": "Change the instance's security group to one that denies all inbound and outbound traffic except from a trusted forensic IP / Cambiar el grupo de seguridad de la instancia a uno que deniegue todo el tráfico entrante y saliente, excepto desde una IP forense de confianza", "explicacion": "Changing the security group is a fast and effective way to isolate the instance. It cuts off communication with other resources and the internet but preserves the instance's state (memory, disk) for live forensic analysis. Terminating the instance destroys evidence. / Cambiar el grupo de seguridad es una forma rápida y efectiva de aislar la instancia. Corta la comunicación con otros recursos e internet pero preserva el estado de la instancia (memoria, disco) para un análisis forense en vivo. Terminar la instancia destruye la evidencia." },
        { "area": 5, "pregunta": "You receive a GuardDuty finding for `UnauthorizedAccess:EC2/MaliciousIPCaller.Custom`. What does this finding indicate? / Recibes un hallazgo de GuardDuty de `UnauthorizedAccess:EC2/MaliciousIPCaller.Custom`. ¿Qué indica este hallazgo?", "opciones": ["An EC2 instance is scanning for open ports on your other instances / Una instancia EC2 está escaneando puertos abiertos en tus otras instancias", "Traffic from one of your EC2 instances is being denied by a network ACL / El tráfico de una de tus instancias EC2 está siendo denegado por una ACL de red", "An EC2 instance is communicating with an IP address included on a custom threat list you provided / Una instancia EC2 se está comunicando con una dirección IP incluida en una lista de amenazas personalizada que tú proporcionaste", "A user has logged into an EC2 instance using a password instead of an SSH key / Un usuario ha iniciado sesión en una instancia EC2 usando una contraseña en lugar de una clave SSH"], "respuesta_correcta": "An EC2 instance is communicating with an IP address included on a custom threat list you provided / Una instancia EC2 se está comunicando con una dirección IP incluida en una lista de amenazas personalizada que tú proporcionaste", "explicacion": "GuardDuty allows you to upload your own threat intelligence lists. This finding means that an EC2 instance made a connection to an IP address that is on one of your custom lists of known malicious IPs. / GuardDuty te permite subir tus propias listas de inteligencia de amenazas. Este hallazgo significa que una instancia EC2 estableció una conexión con una dirección IP que está en una de tus listas personalizadas de IPs maliciosas conocidas." },
        { "area": 5, "pregunta": "What is the primary function of an AWS WAF web ACL? / ¿Cuál es la función principal de una ACL web de AWS WAF?", "opciones": ["To perform DDoS mitigation at the network layer / Para realizar mitigación de DDoS en la capa de rede", "To inspect HTTP/HTTPS requests and block common web-based attacks like SQL injection and XSS / Para inspeccionar las solicitudes HTTP/HTTPS y bloquear ataques comunes basados en la web como la inyección SQL y XSS", "To log all API calls made to your AWS resources / Para registrar todas las llamadas a la API realizadas a tus recursos de AWS", "To provide a private, dedicated network connection from your on-premises data center to AWS / Para proporcionar una conexión de red privada y dedicada desde tu centro de datos on-premises a AWS"], "respuesta_correcta": "To inspect HTTP/HTTPS requests and block common web-based attacks like SQL injection and XSS / Para inspeccionar las solicitudes HTTP/HTTPS y bloquear ataques comunes basados en la web como la inyección SQL y XSS", "explicacion": "AWS WAF is a web application firewall that operates at Layer 7. It allows you to create rules to filter web traffic based on conditions like IP addresses, HTTP headers, URI strings, and request bodies to protect against common attacks. / AWS WAF es un firewall de aplicaciones web que opera en la Capa 7. Te permite crear reglas para filtrar el tráfico web basadas en condiciones como direcciones IP, cabeceras HTTP, cadenas de URI y cuerpos de solicitud para proteger contra ataques comunes." },
        { "area": 5, "pregunta": "An automated process detects that an IAM user's access keys have been exposed on a public GitHub repository. What is the MOST critical and immediate automated remediation action? / Un proceso automatizado detecta que las claves de acceso de un usuario de IAM han sido expuestas en un repositorio público de GitHub. ¿Cuál es la acción de remediación automatizada MÁS crítica e inmediata?", "opciones": ["Send an email notification to the security team / Enviar una notificación por correo electrónico al equipo de seguridad", "Add a 'DenyAll' policy to the IAM user / Añadir una política 'DenyAll' al usuario de IAM", "Revoke all active sessions for the IAM user and deactivate the access keys / Revocar todas las sesiones activas para el usuario de IAM y desactivar las claves de acceso", "Delete the IAM user / Eliminar el usuario de IAM"], "respuesta_correcta": "Revoke all active sessions for the IAM user and deactivate the access keys / Revocar todas las sesiones activas para el usuario de IAM y desactivar las claves de acceso", "explicacion": "The immediate goal is to invalidate the compromised credentials. Deactivating the keys prevents them from being used for new sessions, and revoking active sessions terminates any current access. This contains the breach without being as destructive as deleting the user. / El objetivo inmediato es invalidar las credenciales comprometidas. Desactivar las claves evita que se usen para nuevas sesiones, y revocar las sesiones activas termina cualquier acceso actual. Esto contiene la brecha sin ser tan destructivo como eliminar al usuario." },
        { "area": 5, "pregunta": "You need to automate a multi-step incident response workflow, such as isolating an instance, taking a snapshot, and notifying a team. Which service is best suited for orchestrating these steps? / Necesitas automatizar un flujo de trabajo de respuesta a incidentes de varios pasos, como aislar una instancia, tomar una instantánea y notificar a un equipo. ¿Qué servicio es el más adecuado para orquestar estos pasos?", "opciones": ["AWS Lambda", "AWS Step Functions", "AWS Systems Manager Automation", "Amazon EventBridge"], "respuesta_correcta": "AWS Systems Manager Automation", "explicacion": "SSM Automation is specifically designed to create runbooks for operational and incident response tasks. It can orchestrate a sequence of steps involving various AWS services (like EC2, IAM, SNS) and includes features for branching, error handling, and manual approvals. / SSM Automation está diseñado específicamente para crear manuales de procedimientos (runbooks) para tareas operativas y de respuesta a incidentes. Puede orquestar una secuencia de pasos que involucran varios servicios de AWS (como EC2, IAM, SNS) e incluye características para ramificación, manejo de errores y aprobaciones manuales." },
        { "area": 5, "pregunta": "A CloudWatch alarm triggers due to a critical application failure. You want to ensure the on-call engineer is paged and that the issue is automatically tracked in your ticketing system. How would you configure this? / una alarma de CloudWatch se activa debido a un fallo crítico de la aplicación. Quieres asegurar que el ingeniero de guardia sea localizado (paged) y que el problema se rastree automáticamente en tu sistema de tickets. ¿Cómo configurarías esto?", "opciones": ["Configure the alarm to directly invoke a Lambda function that handles both actions / Configurar la alarma para invocar directamente una función Lambda que maneje ambas acciones", "Configure the alarm to notify an SNS topic. The SNS topic has two subscriptions: one for the paging service and one for a Lambda function that creates the ticket / Configurar la alarma para notificar a un tema de SNS. El tema de SNS tiene dos suscripciones: una para el servicio de localización y otra para una función Lambda que crea el ticket", "Configure the alarm to trigger an SSM Automation document / Configurar la alarma para activar un documento de SSM Automation", "Configure the alarm to send an email via SES / Configurar la alarma para enviar un correo electrónico a través de SES"], "respuesta_correcta": "Configure the alarm to notify an SNS topic. The SNS topic has two subscriptions: one for the paging service and one for a Lambda function that creates the ticket / Configurar la alarma para notificar a un tema de SNS. El tema de SNS tiene dos suscripciones: una para el servicio de localización y otra para una función Lambda que crea el ticket", "explicacion": "SNS provides a fan-out architecture. This is the most decoupled and scalable way to trigger multiple independent actions from a single event. The paging service can subscribe directly via HTTPS/email, and the ticketing integration can be handled by a Lambda function. / SNS proporciona una arquitectura de distribución (fan-out). Esta es la forma más desacoplada y escalable de activar múltiples acciones independientes a partir de un solo evento. El servicio de localización puede suscribirse directamente a través de HTTPS/correo electrónico, y la integración del sistema de tickets puede ser manejada por una función Lambda." },
        { "area": 5, "pregunta": "During a forensic investigation, you need to analyze the memory of a potentially compromised EC2 instance. What is the first step you must take to preserve the memory state? / Durante una investigación forense, necesitas analizar la memoria de una instancia EC2 potencialmente comprometida. ¿Cuál es el primer paso que debes dar para preservar el estado de la memoria?", "opciones": ["Stop the instance", "Take a snapshot of the root EBS volume / Tomar una instantánea del volumen EBS raíz", "Isolate the instance using security groups / Aislar la instancia usando grupos de seguridad", "Do not stop or reboot the instance, as this will erase the memory contents / No detener ni reiniciar la instancia, ya que esto borrará el contenido de la memoria"], "respuesta_correcta": "Do not stop or reboot the instance, as this will erase the memory contents / No detener ni reiniciar la instancia, ya que esto borrará el contenido de la memoria", "explicacion": "The data in an instance's memory (RAM) is volatile and is lost when the instance is stopped or rebooted. The first rule of live memory forensics is to preserve this volatile data by capturing it before taking any other action. / Los datos en la memoria de una instancia (RAM) son volátiles y se pierden cuando la instancia se detiene o reinicia. La primera regla del análisis forense de memoria en vivo es preservar estos datos volátiles capturándolos antes de realizar cualquier otra acción." },
        { "area": 5, "pregunta": "Which service allows you to centrally manage and automate incident response plans across your AWS accounts? / ¿Qué servicio te permite gestionar y automatizar de forma centralizada los planes de respuesta a incidentes en tus cuentas de AWS?", "opciones": ["AWS Security Hub", "AWS Systems Manager Incident Manager", "Amazon Detective", "AWS Control Tower"], "respuesta_correcta": "AWS Systems Manager Incident Manager", "explicacion": "Incident Manager is a dedicated service for incident management. It helps you prepare for incidents with automated response plans that bring the right people and information together, and provides tools for tracking and post-incident analysis. / Incident Manager es un servicio dedicado a la gestión de incidentes. Te ayuda a prepararte para los incidentes con planes de respuesta automatizados que reúnen a las personas y la información adecuadas, y proporciona herramientas para el seguimiento y el análisis post-incidente." },
        { "area": 5, "pregunta": "An EventBridge rule is configured to trigger on a specific event, but it's not firing. Which of the following is NOT a likely cause? / una regla de EventBridge está configurada para activarse con un evento específico, pero no se está disparando. ¿Cuál de las siguientes NO es una causa probable?", "opciones": ["The event pattern in the rule does not exactly match the structure of the incoming event / El patrón de evento en la regla no coincide exactamente con la estructura del evento entrante", "The IAM role associated with the target does not have the necessary permissions / El rol de IAM asociado con el destino no tiene los permisos necesarios", "The event bus that is receiving the event is different from the one the rule is on / El bus de eventos que recibe el evento es diferente de aquel en el que se encuentra la regla", "The target service (e.g., Lambda) is throttled / El servicio de destino (ej: Lambda) está siendo estrangulado (throttled)"], "respuesta_correcta": "The target service (e.g., Lambda) is throttled / El servicio de destino (ej: Lambda) está siendo estrangulado (throttled)", "explicacion": "If the target service is throttled, the rule itself would still fire and EventBridge would attempt to invoke the target. This would result in invocation errors or retries, which would be visible in metrics, but it wouldn't prevent the rule from matching and firing in the first place. / Si el servicio de destino está siendo estrangulado, la regla en sí se dispararía y EventBridge intentaría invocar el destino. Esto resultaría en errores de invocación o reintentos, que serían visibles en las métricas, pero no evitaría que la regla coincida y se dispare en primer lugar." },
        { "area": 5, "pregunta": "What is the function of the 'trusted advisor' service in the context of event response? / ¿Cuál es la función del servicio 'Trusted Advisor' en el contexto de la respuesta a eventos?", "opciones": ["To provide real-time recommendations on cost optimization and security before an incident occurs / Para proporcionar recomendaciones en tiempo real sobre optimización de costos y seguridad antes de que ocurra un incidente", "To automatically remediate non-compliant resources detected during an incident / Para remediar automáticamente los recursos no conformes detectados durante un incidente", "To trace API calls and user activity for forensic analysis / Para rastrear llamadas a la API y la actividad del usuario para análisis forense", "To detect and respond to DDoS attacks / Para detectar y responder a ataques DDoS"], "respuesta_correcta": "To provide real-time recommendations on cost optimization and security before an incident occurs / Para proporcionar recomendaciones en tiempo real sobre optimización de costos y seguridad antes de que ocurra un incidente", "explicacion": "Trusted Advisor acts as a proactive tool. It inspects your AWS environment and makes recommendations that can help you close security gaps (like open security groups) and improve resilience, thus preventing future incidents. / Trusted Advisor actúa como una herramienta proactiva. Inspecciona tu entorno de AWS y hace recomendaciones que pueden ayudarte a cerrar brechas de seguridad (como grupos de seguridad abiertos) y mejorar la resiliencia, previniendo así futuros incidentes." },
        { "area": 5, "pregunta": "You suspect an EC2 instance is generating malicious traffic. You need to analyze this traffic without alerting a potential attacker. Which service should you use? / Sospechas que una instancia EC2 está generando tráfico malicioso. Necesitas analizar este tráfico sin alertar a un posible atacante. ¿Qué servicio deberías usar?", "opciones": ["VPC Flow Logs", "VPC Traffic Mirroring", "AWS CloudTrail", "AWS Network Firewall"], "respuesta_correcta": "VPC Traffic Mirroring", "explicacion": "Traffic Mirroring allows you to passively copy network traffic from an ENI of an EC2 instance and send it to an out-of-band security appliance or monitoring tool for deep packet inspection. It's invisible to the source instance. / El Espejado de Tráfico te permite copiar pasivamente el tráfico de red de una ENI de una instancia EC2 y enviarlo a un dispositivo de seguridad o herramienta de monitorización fuera de banda para una inspección profunda de paquetes. Es invisible para la instancia de origen." },
        { "area": 5, "pregunta": "After a security incident, your team needs to review all API calls made by a specific IAM role over the past 30 days. Which service provides this information? / Después de un incidente de seguridad, tu equipo necesita revisar todas las llamadas a la API realizadas por un rol de IAM específico durante los últimos 30 días. ¿Qué servicio proporciona esta información?", "opciones": ["Amazon GuardDuty", "AWS Security Hub", "AWS CloudTrail", "VPC Flow Logs"], "respuesta_correcta": "AWS CloudTrail", "explicacion": "CloudTrail is the audit log for your AWS account. It records API activity, and you can use CloudTrail Lake or Amazon Athena to query the logs to find all actions performed by a specific IAM principal within a given time frame. / CloudTrail es el registro de auditoría de tu cuenta de AWS. Registra la actividad de la API, y puedes usar CloudTrail Lake o Amazon Athena para consultar los logs y encontrar todas las acciones realizadas por un principal de IAM específico dentro de un marco de tiempo determinado." },
        { "area": 5, "pregunta": "What is the purpose of the 'Schema Registry' in Amazon EventBridge? / ¿Cuál es el propósito del 'Registro de Esquemas' en Amazon EventBridge?", "opciones": ["To define the IAM policies for event buses / Para definir las políticas de IAM para los buses de eventos", "To store and manage the structure (schema) of events, allowing for code generation and validation / Para almacenar y gestionar la estructura (esquema) de los eventos, permitiendo la generación de código y la validación", "To archive events for long-term retention and replay / Para archivar eventos para retención a largo plazo y reproducción", "To route events to different targets based on their content / Para enrutar eventos a diferentes destinos según su contenido"], "respuesta_correcta": "To store and manage the structure (schema) of events, allowing for code generation and validation / Para almacenar y gestionar la estructura (esquema) de los eventos, permitiendo la generación de código y la validación", "explicacion": "The Schema Registry allows you to discover, create, and manage OpenAPI or JSONSchema Draft4 schemas for events. This helps developers by enabling code generation for events in their IDE and can be used to validate event structures. / El Registro de Esquemas te permite descubrir, crear y gestionar esquemas OpenAPI o JSONSchema Draft4 para eventos. Esto ayuda a los desarrolladores al permitir la generación de código para eventos en su IDE y se puede usar para validar las estructuras de los eventos." },
        { "area": 5, "pregunta": "An S3 bucket has been accidentally made public. Which service can automatically detect and help remediate this configuration drift? / Un bucket de S3 se ha hecho público accidentalmente. ¿Qué servicio puede detectar automáticamente y ayudar a remediar esta desviación de la configuración?", "opciones": ["Amazon Macie", "AWS Config", "Amazon S3 Storage Lens", "AWS Trusted Advisor"], "respuesta_correcta": "AWS Config", "explicacion": "AWS Config continuously monitors and records your AWS resource configurations. You can use managed rules (like `s3-bucket-public-read-prohibited`) to detect when a resource becomes non-compliant and trigger automated remediation. / AWS Config monitorea y registra continuamente las configuraciones de tus recursos de AWS. Puedes usar reglas administradas (como `s3-bucket-public-read-prohibited`) para detectar cuándo un recurso deja de ser conforme y activar la remediación automatizada." },
        { "area": 5, "pregunta": "You are creating an EventBridge rule to match events from an S3 bucket. The event pattern needs to trigger only for `.jpg` files being uploaded. How should you structure the filter? / Estás creando una regla de EventBridge para que coincida con eventos de un bucket de S3. El patrón de evento necesita activarse solo para la subida de archivos `.jpg`. ¿Cómo deberías estructurar el filtro?", "opciones": ["Use a prefix filter on the object key / Usar un filtro de prefijo en la clave del objeto", "Use a suffix filter on the object key / Usar un filtro de sufijo en la clave del objeto", "Use a 'starts-with' comparison / Usar una comparación 'starts-with'", "Use a 'regex' match / Usar una coincidencia 'regex'"], "respuesta_correcta": "Use a suffix filter on the object key / Usar un filtro de sufijo en la clave del objeto", "explicacion": "EventBridge event patterns support suffix matching, which is ideal for filtering based on file extensions. The filter would look like: `\"object\": {\"key\": [{\"suffix\": \".jpg\"}]}`. / Los patrones de evento de EventBridge admiten la coincidencia por sufijo, lo cual es ideal para filtrar según las extensiones de archivo. El filtro se vería así: `\"object\": {\"key\": [{\"suffix\": \".jpg\"}]}`." },
        { "area": 5, "pregunta": "During an incident, you need to grant a developer temporary, emergency access to a production EC2 instance. What is the most secure way to do this? / Durante un incidente, necesitas otorgar a un desarrollador acceso temporal y de emergencia a una instancia EC2 de producción. ¿Cuál es la forma más segura de hacerlo?", "opciones": ["Create a new IAM user with an admin policy and share the access keys / Crear un nuevo usuario de IAM con una política de administrador y compartir las claves de acceso", "Use AWS Systems Manager Session Manager to provide secure, shell-level access without opening inbound ports or managing SSH keys / Usar AWS Systems Manager Session Manager para proporcionar acceso seguro a nivel de shell sin abrir puertos de entrada ni gestionar claves SSH", "Temporarily add the developer's public SSH key to the instance's `authorized_keys` file / Añadir temporalmente la clave SSH pública del desarrollador al archivo `authorized_keys` de la instancia", "Ask the developer to use the EC2 serial console / Pedir al desarrollador que use la consola serie de EC2"], "respuesta_correcta": "Use AWS Systems Manager Session Manager to provide secure, shell-level access without opening inbound ports or managing SSH keys / Usar AWS Systems Manager Session Manager para proporcionar acceso seguro a nivel de shell sin abrir puertos de entrada ni gestionar claves SSH", "explicacion": "Session Manager is the recommended best practice for interactive instance access. It provides a secure, auditable, and managed way to get a shell without the risks of exposed SSH ports, bastion hosts, or long-lived keys. / Session Manager es la mejor práctica recomendada para el acceso interactivo a instancias. Proporciona una forma segura, auditable y gestionada de obtener un shell sin los riesgos de los puertos SSH expuestos, los hosts bastión o las claves de larga duración." },
        { "area": 5, "pregunta": "Which AWS service aggregates security findings from services like GuardDuty, Inspector, and Macie into a single, centralized view? / ¿Qué servicio de AWS agrega los hallazgos de seguridad de servicios como GuardDuty, Inspector y Macie en una única vista centralizada?", "opciones": ["AWS Security Hub", "Amazon Detective", "AWS Audit Manager", "AWS Control Tower"], "respuesta_correcta": "AWS Security Hub", "explicacion": "AWS Security Hub is designed to be a single place that aggregates, organizes, and prioritizes your security alerts or findings from multiple AWS services, as well as from AWS Partner solutions. / AWS Security Hub está diseñado para ser un único lugar que agrega, organiza y prioriza tus alertas o hallazgos de seguridad de múltiples servicios de AWS, así como de soluciones de socios de AWS." },
        { "area": 5, "pregunta": "An application is experiencing intermittent errors. You suspect it might be related to AWS API throttling. Which service provides the best visibility into API calls that are being throttled? / Una aplicación está experimentando errores intermitentes. Sospechas que podría estar relacionado con la limitación (throttling) de la API de AWS. ¿Qué servicio proporciona la mejor visibilidad de las llamadas a la API que están siendo limitadas?", "opciones": ["AWS X-Ray", "AWS CloudTrail", "Amazon CloudWatch ServiceLens", "VPC Flow Logs"], "respuesta_correcta": "AWS CloudTrail", "explicacion": "When an AWS API call is throttled, it returns a specific error code (e.g., `ThrottlingException`). These failed API calls are recorded in CloudTrail, which allows you to search for these specific error codes to identify which services and principals are being throttled. / Cuando una llamada a la API de AWS es limitada, devuelve un código de error específico (ej: `ThrottlingException`). Estas llamadas a la API fallidas se registran en CloudTrail, lo que te permite buscar estos códigos de error específicos para identificar qué servicios y principales están siendo limitados." },
        { "area": 5, "pregunta": "You are setting up an Amazon EventBridge rule for an operational event. What is the difference between an 'event pattern' and an 'input transformer'? / Estás configurando una regla de Amazon EventBridge para un evento operativo. ¿Cuál es la diferencia entre un 'patrón de evento' y un 'transformador de entrada'?", "opciones": ["An event pattern filters events, while an input transformer modifies the event payload before sending it to the target / Un patrón de evento filtra los eventos, mientras que un transformador de entrada modifica la carga útil del evento antes de enviarla al destino", "An event pattern modifies the event payload, while an input transformer filters events / Un patrón de evento modifica la carga útil del evento, mientras que un transformador de entrada filtra los eventos", "They are two names for the same feature / Son dos nombres para la misma característica", "An event pattern is for AWS events, while an input transformer is for custom events / Un patrón de evento es para eventos de AWS, mientras que un transformador de entrada es para eventos personalizados"], "respuesta_correcta": "An event pattern filters events, while an input transformer modifies the event payload before sending it to the target / Un patrón de evento filtra los eventos, mientras que un transformador de entrada modifica la carga útil del evento antes de enviarla al destino", "explicacion": "The event pattern is used by the rule to decide IF it should trigger on an incoming event. If it matches, the input transformer can then be used to customize the JSON payload of the event that is passed to the target, making it easier for the target to process. / El patrón de evento es utilizado por la regla para decidir SI debe activarse con un evento entrante. Si coincide, el transformador de entrada puede usarse para personalizar la carga útil JSON del evento que se pasa al destino, facilitando su procesamiento por parte del destino." }
    ],
    "area6": [
        { "area": 6, "pregunta": "You need to ensure that all objects uploaded to an S3 bucket are encrypted at rest. What is the most straightforward way to enforce this policy? / Necesitas asegurar que todos los objetos subidos a un bucket de S3 estén cifrados en reposo. ¿Cuál es la forma más directa de aplicar esta política?", "opciones": ["Enable a default encryption configuration on the S3 bucket / Habilitar una configuración de cifrado por defecto en el bucket de S3", "Use an IAM policy to deny uploads that do not have the encryption header / Usar una política de IAM para denegar subidas que no tengan la cabecera de cifrado", "Create a Lambda function triggered on S3 uploads to encrypt objects / Crear una función Lambda que se active con las subidas a S3 para cifrar objetos", "Use a bucket policy that denies `s3:PutObject` if the `x-amz-server-side-encryption` header is not present / Usar una política de bucket que deniegue `s3:PutObject` si la cabecera `x-amz-server-side-encryption` no está presente"], "respuesta_correcta": "Use a bucket policy that denies `s3:PutObject` if the `x-amz-server-side-encryption` header is not present / Usar una política de bucket que deniegue `s3:PutObject` si la cabecera `x-amz-server-side-encryption` no está presente", "explicacion": "While default encryption is good, a bucket policy is the strongest enforcement mechanism. It explicitly denies any upload request that doesn't include the required encryption header, ensuring no unencrypted object can be written. / Aunque el cifrado por defecto es bueno, una política de bucket es el mecanismo de aplicación más fuerte. Deniega explícitamente cualquier solicitud de subida que no incluya la cabecera de cifrado requerida, asegurando que ningún objeto sin cifrar pueda ser escrito." },
        { "area": 6, "pregunta": "Which AWS service helps you automate the process of auditing your AWS usage to ensure you are compliant with standards like PCI DSS and HIPAA? / ¿Qué servicio de AWS te ayuda a automatizar el proceso de auditar tu uso de AWS para asegurar que cumples con estándares como PCI DSS y HIPAA?", "opciones": ["AWS Trusted Advisor", "AWS Audit Manager", "Amazon Inspector", "AWS Security Hub"], "respuesta_correcta": "AWS Audit Manager", "explicacion": "AWS Audit Manager is specifically designed to help you continuously audit your AWS usage to simplify how you assess risk and compliance. It provides prebuilt frameworks for common standards (PCI DSS, HIPAA, etc.) and automates evidence collection. / AWS Audit Manager está diseñado específicamente para ayudarte a auditar continuamente tu uso de AWS para simplificar la evaluación de riesgos y el cumplimiento. Proporciona marcos predefinidos para estándares comunes (PCI DSS, HIPAA, etc.) y automatiza la recopilación de evidencia." },
        { "area": 6, "pregunta": "You must ensure that developers cannot launch EC2 instances that are not from an approved list of AMIs. How can this be enforced? / Debes asegurar que los desarrolladores no puedan lanzar instancias EC2 que no provengan de una lista de AMIs aprobadas. ¿Cómo se puede aplicar esto?", "opciones": ["Using an AWS Config rule to detect non-approved AMIs / Usando una regla de AWS Config para detectar AMIs no aprobadas", "Using an IAM policy with a condition that checks the `ec2:ImageID` of the instance being launched / Usando una política de IAM con una condición que verifique el `ec2:ImageID` de la instancia que se está lanzando", "Using a security group to block traffic from instances with non-approved AMIs / Usando un grupo de seguridad para bloquear el tráfico de instancias con AMIs no aprobadas", "Using AWS Service Catalog to provide a portfolio of approved products / Usando AWS Service Catalog para proporcionar un portafolio de productos aprobados"], "respuesta_correcta": "Using an IAM policy with a condition that checks the `ec2:ImageID` of the instance being launched / Usando una política de IAM con una condición que verifique el `ec2:ImageID` de la instancia que se está lanzando", "explicacion": "An IAM policy with a `Condition` block is a preventative control. You can explicitly deny the `ec2:RunInstances` action if the `ec2:ImageID` parameter in the request does not match one of the AMIs in your approved list. / Una política de IAM con un bloque de `Condition` es un control preventivo. Puedes denegar explícitamente la acción `ec2:RunInstances` si el parámetro `ec2:ImageID` en la solicitud no coincide con una de las AMIs en tu lista aprobada." },
        { "area": 6, "pregunta": "What is the primary purpose of an VPC Gateway Endpoint for S3 and DynamoDB? / ¿Cuál es el propósito principal de un VPC Gateway Endpoint para S3 y DynamoDB?", "opciones": ["To allow resources in a private subnet to access S3 and DynamoDB using a NAT Gateway / Para permitir que los recursos en una subred privada accedan a S3 y DynamoDB usando un NAT Gateway", "To provide secure access to S3 and DynamoDB from your VPC without traffic leaving the AWS network / Para proporcionar acceso seguro a S3 y DynamoDB desde tu VPC sin que el tráfico abandone la red de AWS", "To encrypt the traffic between your VPC and S3/DynamoDB / Para cifrar el tráfico entre tu VPC y S3/DynamoDB", "To accelerate data transfer speeds to S3 and DynamoDB / Para acelerar las velocidades de transferencia de datos a S3 y DynamoDB"], "respuesta_correcta": "To provide secure access to S3 and DynamoDB from your VPC without traffic leaving the AWS network / Para proporcionar acceso seguro a S3 y DynamoDB desde tu VPC sin que el tráfico abandone la red de AWS", "explicacion": "Gateway Endpoints provide a private and secure connection. When you use one, the traffic between your VPC and the service does not traverse the public internet, which enhances security and can reduce data transfer costs. / Los Gateway Endpoints proporcionan una conexión privada y segura. Cuando usas uno, el tráfico entre tu VPC y el servicio no atraviesa el internet público, lo que mejora la seguridad y puede reducir los costos de transferencia de datos." },
        { "area": 6, "pregunta": "Which service should be used to manage and rotate database credentials, API keys, and other secrets used by your application? / ¿Qué servicio debería usarse para gestionar y rotar credenciales de bases de datos, claves de API y otros secretos usados por tu aplicación?", "opciones": ["AWS IAM", "AWS Systems Manager Parameter Store (Standard Tier)", "AWS Secrets Manager", "AWS Key Management Service (KMS)"], "respuesta_correcta": "AWS Secrets Manager", "explicacion": "AWS Secrets Manager is the ideal service for this. It provides features like fine-grained access control, integration with RDS for automatic credential rotation, and cross-account access, which are critical for managing the lifecycle of secrets securely. / AWS Secrets Manager es el servicio ideal para esto. Proporciona características como control de acceso detallado, integración con RDS para la rotación automática de credenciales y acceso entre cuentas, que son críticos para gestionar el ciclo de vida de los secretos de forma segura." },
        { "area": 6, "pregunta": "You need to provide a third-party auditor with read-only access to your AWS environment to review configurations. What is the most secure way to grant this access? / Necesitas proporcionar a un auditor externo acceso de solo lectura a tu entorno de AWS para revisar las configuraciones. ¿Cuál es la forma más segura de otorgar este acceso?", "opciones": ["Create an IAM user for the auditor with the `ReadOnlyAccess` managed policy / Crear un usuario de IAM para el auditor con la política administrada `ReadOnlyAccess`", "Create a cross-account IAM role with read-only permissions that the auditor's AWS account can assume / Crear un rol de IAM entre cuentas con permisos de solo lectura que la cuenta de AWS del auditor pueda asumir", "Share the root user credentials with the auditor / Compartir las credenciales del usuario raíz con el auditor", "Launch an EC2 instance with an IAM role and give the auditor SSH access / Lanzar una instancia EC2 con un rol de IAM y darle al auditor acceso SSH"], "respuesta_correcta": "Create a cross-account IAM role with read-only permissions that the auditor's AWS account can assume / Crear un rol de IAM entre cuentas con permisos de solo lectura que la cuenta de AWS del auditor pueda asumir", "explicacion": "Using a cross-account role is the AWS best practice. It avoids the need to create and manage long-term IAM user credentials. The auditor can assume the role from their own trusted AWS account, and access can be easily revoked. / Usar un rol entre cuentas es la mejor práctica de AWS. Evita la necesidad de crear y gestionar credenciales de usuario de IAM a largo plazo. El auditor puede asumir el rol desde su propia cuenta de AWS de confianza, y el acceso puede ser revocado fácilmente." },
        { "area": 6, "pregunta": "What is the function of AWS KMS Envelope Encryption? / ¿Cuál es la función del Cifrado de Sobre de AWS KMS?", "opciones": ["It encrypts the KMS Customer Master Key (CMK) itself / Cifra la propia Clave Maestra de Cliente (CMK) de KMS", "It's a process where a data key is used to encrypt data, and that data key is then encrypted by a KMS CMK / Es un proceso donde una clave de datos se usa para cifrar datos, y esa clave de datos es luego cifrada por una CMK de KMS", "It's a method for encrypting email messages sent via SES / Es un método para cifrar mensajes de correo electrónico enviados a través de SES", "It is the default encryption method for EBS volumes / Es el método de cifrado por defecto para los volúmenes EBS"], "respuesta_correcta": "It's a process where a data key is used to encrypt data, and that data key is then encrypted by a KMS CMK / Es un proceso donde una clave de datos se usa para cifrar datos, y esa clave de datos es luego cifrada por una CMK de KMS", "explicacion": "Envelope encryption is a common and powerful pattern. It allows you to encrypt large amounts of data locally using a performant data key, while the highly protected and audited KMS CMK is only used to encrypt/decrypt the small data key itself. / El cifrado de sobre es un patrón común y potente. Te permite cifrar grandes cantidades de datos localmente usando una clave de datos de alto rendimiento, mientras que la CMK de KMS, altamente protegida y auditada, solo se usa para cifrar/descifrar la pequeña clave de datos." },
        { "area": 6, "pregunta": "Which service helps you identify and classify sensitive data, such as Personally Identifiable Information (PII), stored in your Amazon S3 buckets? / ¿Qué servicio te ayuda a identificar y clasificar datos sensibles, como Información de Identificación Personal (PII), almacenados en tus buckets de Amazon S3?", "opciones": ["Amazon Inspector", "Amazon GuardDuty", "Amazon Macie", "AWS Shield"], "respuesta_correcta": "Amazon Macie", "explicacion": "Amazon Macie is a data security and privacy service that uses machine learning and pattern matching to discover, classify, and protect sensitive data in Amazon S3. / Amazon Macie es un servicio de seguridad y privacidad de datos que utiliza aprendizaje automático y coincidencia de patrones para descubrir, clasificar y proteger datos sensibles en Amazon S3." },
        { "area": 6, "pregunta": "What is the purpose of a Network ACL (NACL) in a VPC? / ¿Cuál es el propósito de una ACL de Red (NACL) en una VPC?", "opciones": ["To act as a stateful firewall for EC2 instances / Para actuar como un firewall con estado para las instancias EC2", "To act as a stateless firewall for subnets, evaluating inbound and outbound traffic rules / Para actuar como un firewall sin estado para las subredes, evaluando las reglas de tráfico entrante y saliente", "To control traffic between subnets in the same VPC / Para controlar el tráfico entre subredes en la misma VPC", "To provide a private connection to AWS services / Para proporcionar una conexión privada a los servicios de AWS"], "respuesta_correcta": "To act as a stateless firewall for subnets, evaluating inbound and outbound traffic rules / Para actuar como un firewall sin estado para las subredes, evaluando las reglas de tráfico entrante y saliente", "explicacion": "NACLs are stateless, meaning you must define separate rules for both inbound and outbound traffic. They operate at the subnet level and act as a first line of defense before traffic reaches the stateful security groups. / Las NACLs son sin estado, lo que significa que debes definir reglas separadas tanto para el tráfico entrante como para el saliente. Operan a nivel de subred y actúan como una primera línea de defensa antes de que el tráfico llegue a los grupos de seguridad con estado." },
        { "area": 6, "pregunta": "You need to provide temporary, short-lived credentials to an application running on an EC2 instance so it can access other AWS services. What is the most secure method? / Necesitas proporcionar credenciales temporales y de corta duración a una aplicación que se ejecuta en una instancia EC2 para que pueda acceder a otros servicios de AWS. ¿Cuál es el método más seguro?", "opciones": ["Store IAM user access keys in a configuration file on the instance / Almacenar las claves de acceso de un usuario de IAM en un archivo de configuración en la instancia", "Generate long-term credentials and encrypt them using KMS / Generar credenciales a largo plazo y cifrarlas usando KMS", "Assign an IAM Role to the EC2 instance profile / Asignar un Rol de IAM al perfil de la instancia EC2", "Hardcode the credentials directly into the application source code / Escribir las credenciales directamente en el código fuente de la aplicación"], "respuesta_correcta": "Assign an IAM Role to the EC2 instance profile / Asignar un Rol de IAM al perfil de la instancia EC2", "explicacion": "Using an IAM role is the absolute best practice. The EC2 instance automatically retrieves temporary credentials via its metadata service, eliminating the need to store any long-term keys on the instance, which is a major security risk. / Usar un rol de IAM es la mejor práctica absoluta. La instancia EC2 recupera automáticamente credenciales temporales a través de su servicio de metadatos, eliminando la necesidad de almacenar claves a largo plazo en la instancia, lo cual es un riesgo de seguridad importante." },
        { "area": 6, "pregunta": "Which AWS service provides a formal document detailing AWS's security controls and compliance with various standards, which you can provide to your auditors? / ¿Qué servicio de AWS proporciona un documento formal que detalla los controles de seguridad y el cumplimiento de AWS con varios estándares, que puedes proporcionar a tus auditores?", "opciones": ["AWS Trusted Advisor", "AWS Artifact", "AWS Audit Manager", "AWS Security Hub"], "respuesta_correcta": "AWS Artifact", "explicacion": "AWS Artifact is your go-to, central resource for compliance-related information. It provides on-demand access to AWS's security and compliance reports (e.g., SOC, PCI, ISO reports) and select online agreements. / AWS Artifact es tu recurso central de referencia para información relacionada con el cumplimiento. Proporciona acceso bajo demanda a los informes de seguridad y cumplimiento de AWS (ej: informes SOC, PCI, ISO) y acuerdos en línea seleccionados." },
        { "area": 6, "pregunta": "What does the principle of 'least privilege' mean when creating IAM policies? / ¿Qué significa el principio de 'privilegio mínimo' al crear políticas de IAM?", "opciones": ["Granting all users administrator access to simplify management / Otorgar a todos los usuarios acceso de administrador para simplificar la gestión", "Granting only the specific permissions required to perform a specific task, and no more / Otorgar solo los permisos específicos necesarios para realizar una tarea específica, y no más", "Allowing all actions from trusted IP ranges / Permitir todas las acciones desde rangos de IP de confianza", "Creating one large policy and attaching it to all users and roles / Crear una política grande y adjuntarla a todos los usuarios y roles"], "respuesta_correcta": "Granting only the specific permissions required to perform a specific task, and no more / Otorgar solo los permisos específicos necesarios para realizar una tarea específica, y no más", "explicacion": "This is a fundamental security principle. By scoping down permissions to the absolute minimum required, you reduce the potential blast radius if a user's credentials or a role is ever compromised. / Este es un principio de seguridad fundamental. Al reducir los permisos al mínimo absoluto requerido, reduces el radio de impacto potencial si las credenciales de un usuario o un rol se ven comprometidos." },
        { "area": 6, "pregunta": "You need to filter outbound traffic from a private subnet to allow access only to specific FQDNs (e.g., `github.com`, `packages.example.com`). Which service can achieve this? / Necesitas filtrar el tráfico saliente de una subred privada para permitir el acceso solo a FQDNs específicos (ej: `github.com`, `packages.example.com`). ¿Qué servicio puede lograr esto?", "opciones": ["Security Groups", "Network ACLs", "AWS Network Firewall", "A NAT Gateway"], "respuesta_correcta": "AWS Network Firewall", "explicacion": "AWS Network Firewall is a stateful, managed firewall service that can filter traffic based on FQDNs (domain names). Security Groups and NACLs can only filter based on IP addresses, and a NAT Gateway only provides internet access without this level of filtering. / AWS Network Firewall es un servicio de firewall administrado y con estado que puede filtrar el tráfico basado en FQDNs (nombres de dominio). Los Grupos de Seguridad y las NACLs solo pueden filtrar por direcciones IP, y un NAT Gateway solo proporciona acceso a internet sin este nivel de filtrado." },
        { "area": 6, "pregunta": "To meet compliance requirements, all data written to a DynamoDB table must be encrypted at rest using a customer-managed KMS key. How do you configure this? / Para cumplir con los requisitos de conformidad, todos los datos escritos en una tabla de DynamoDB deben estar cifrados en reposo usando una clave KMS gestionada por el cliente. ¿Cómo configuras esto?", "opciones": ["Enable default encryption on the S3 bucket where DynamoDB stores data / Habilitar el cifrado por defecto en el bucket de S3 donde DynamoDB almacena los datos", "This is the default behavior and requires no configuration / Este es el comportamiento por defecto y no requiere configuración", "Manually encrypt the data in your application code before writing it to DynamoDB / Cifrar manualmente los datos en el código de tu aplicación antes de escribirlos en DynamoDB", "Select the 'Customer managed key' option in the table's encryption settings and choose your KMS key / Seleccionar la opción 'Clave gestionada por el cliente' en la configuración de cifrado de la tabla y elegir tu clave KMS"], "respuesta_correcta": "Select the 'Customer managed key' option in the table's encryption settings and choose your KMS key / Seleccionar la opción 'Clave gestionada por el cliente' en la configuración de cifrado de la tabla y elegir tu clave KMS", "explicacion": "DynamoDB encrypts all data at rest by default using an AWS-owned key. To meet the requirement of using a customer-managed key, you must explicitly change the encryption settings for the table and specify the CMK you control. / DynamoDB cifra todos los datos en reposo por defecto usando una clave propiedad de AWS. Para cumplir con el requisito de usar una clave gestionada por el cliente, debes cambiar explícitamente la configuración de cifrado de la tabla y especificar la CMK que tú controlas." },
        { "area": 6, "pregunta": "Which IAM entity should be used to grant permissions to an AWS service (like EC2 Auto Scaling) to perform actions on your behalf? / ¿Qué entidad de IAM debería usarse para otorgar permisos a un servicio de AWS (como EC2 Auto Scaling) para que realice acciones en tu nombre?", "opciones": ["IAM User", "IAM Group", "IAM Role", "IAM Policy"], "respuesta_correcta": "IAM Role", "explicacion": "IAM Roles are designed to be assumed by trusted entities. This includes AWS services, users from another AWS account, or users authenticated via an external identity provider. The service assumes the role to get temporary credentials to perform its tasks. / Los Roles de IAM están diseñados para ser asumidos por entidades de confianza. Esto incluye servicios de AWS, usuarios de otra cuenta de AWS o usuarios autenticados a través de un proveedor de identidad externo. El servicio asume el rol para obtener credenciales temporales para realizar sus tareas." },
        { "area": 6, "pregunta": "What is the function of an IAM Permission Boundary? / ¿Cuál es la función de un Límite de Permisos de IAM?", "opciones": ["To define the maximum permissions that an IAM user or role can ever have, even if their identity-based policy allows more / Para definir los permisos máximos que un usuario o rol de IAM puede tener, incluso si su política basada en identidad permite más", "To define which IAM principals are allowed to assume a role / Para definir qué principales de IAM tienen permitido asumir un rol", "To organize users into logical groups for easier management / Para organizar usuarios en grupos lógicos para una gestión más fácil", "To deny a specific set of actions that should never be allowed / Para denegar un conjunto específico de acciones que nunca deberían ser permitidas"], "respuesta_correcta": "To define the maximum permissions that an IAM user or role can ever have, even if their identity-based policy allows more / Para definir los permisos máximos que un usuario o rol de IAM puede tener, incluso si su política basada en identidad permite más", "explicacion": "A permission boundary is an advanced feature used to delegate permissions management safely. It acts as a ceiling. The effective permissions of a user are the intersection of their identity-based policies and their permission boundary. / Un límite de permisos es una característica avanzada que se utiliza para delegar la gestión de permisos de forma segura. Actúa como un techo. Los permisos efectivos de un usuario son la intersección de sus políticas basadas en identidad y su límite de permisos." },
        { "area": 6, "pregunta": "How can you ensure that all CloudTrail logs are immutable and cannot be deleted, even by the root user, for a specified retention period? / ¿Cómo puedes asegurar que todos los logs de CloudTrail sean inmutables y no puedan ser eliminados, ni siquiera por el usuario raíz, durante un período de retención específico?", "opciones": ["Enable CloudTrail log file validation / Habilitar la validación de archivos de log de CloudTrail", "Use an S3 Bucket Policy with an explicit Deny rule / Usar una Política de Bucket de S3 con una regla de Denegación explícita", "Store the logs in an S3 bucket with S3 Object Lock in Compliance mode / Almacenar los logs en un bucket de S3 con S3 Object Lock en modo Cumplimiento", "Enable MFA Delete on the S3 bucket / Habilitar la Eliminación MFA en el bucket de S3"], "respuesta_correcta": "Store the logs in an S3 bucket with S3 Object Lock in Compliance mode / Almacenar los logs en un bucket de S3 con S3 Object Lock en modo Cumplimiento", "explicacion": "S3 Object Lock provides WORM (Write-Once-Read-Many) storage. In Compliance mode, a protected object version can't be overwritten or deleted by any user, including the root user in your AWS account, for the duration of the retention period. / S3 Object Lock proporciona almacenamiento WORM (Escribir una vez, leer muchas). En el modo Cumplimiento, una versión de objeto protegida no puede ser sobrescrita ni eliminada por ningún usuario, incluido el usuario raíz de tu cuenta de AWS, durante el período de retención." },
        { "area": 6, "pregunta": "You are running a containerized application on Amazon ECS. How can you provide granular, least-privilege permissions to the containers themselves? / Estás ejecutando una aplicación en contenedores en Amazon ECS. ¿Cómo puedes proporcionar permisos granulares de privilegio mínimo a los propios contenedores?", "opciones": ["Assign an IAM Role to the underlying EC2 instance / Asignar un Rol de IAM a la instancia EC2 subyacente", "Use IAM Roles for Tasks to assign a specific IAM role to an ECS task / Usar Roles de IAM para Tareas para asignar un rol de IAM específico a una tarea de ECS", "Hardcode IAM user credentials as environment variables in the task definition / Escribir credenciales de usuario de IAM como variables de entorno en la definición de la tarea", "Create a security group for each container / Crear un grupo de seguridad para cada contenedor"], "respuesta_correcta": "Use IAM Roles for Tasks to assign a specific IAM role to an ECS task / Usar Roles de IAM para Tareas para asignar un rol de IAM específico a una tarea de ECS", "explicacion": "IAM Roles for Tasks is the recommended best practice. It allows you to specify an IAM role that can be used by the containers in a task, providing temporary credentials and ensuring that each task only has the permissions it needs, independent of the underlying instance's role. / Los Roles de IAM para Tareas son la mejor práctica recomendada. Te permiten especificar un rol de IAM que pueden usar los contenedores en una tarea, proporcionando credenciales temporales y asegurando que cada tarea solo tenga los permisos que necesita, independientemente del rol de la instancia subyacente." },
        { "area": 6, "pregunta": "Which type of KMS key provides the highest level of security and control, as the key material is generated and managed within a hardware security module (HSM) that you control? / ¿Qué tipo de clave KMS proporciona el nivel más alto de seguridad y control, ya que el material de la clave se genera y gestiona dentro de un módulo de seguridad de hardware (HSM) que tú controlas?", "opciones": ["AWS managed key (AWS/s3)", "Customer managed key (CMK)", "KMS key with imported key material", "KMS key in a Custom Key Store backed by AWS CloudHSM / Clave KMS en un Almacén de Claves Personalizado respaldado por AWS CloudHSM"], "respuesta_correcta": "KMS key in a Custom Key Store backed by AWS CloudHSM / Clave KMS en un Almacén de Claves Personalizado respaldado por AWS CloudHSM", "explicacion": "A Custom Key Store integrates KMS with a CloudHSM cluster that you own and manage. This gives you direct control over the HSMs and the lifecycle of the keys, satisfying stringent compliance requirements where keys must be in a single-tenant, customer-controlled HSM. / Un Almacén de Claves Personalizado integra KMS con un clúster de CloudHSM que posees y gestionas. Esto te da control directo sobre los HSMs y el ciclo de vida de las claves, satisfaciendo estrictos requisitos de cumplimiento donde las claves deben estar en un HSM de un solo inquilino controlado por el cliente." },
        { "area": 6, "pregunta": "What is the purpose of an 'IAM Access Analyzer'? / ¿Cuál es el propósito de un 'Analizador de Acceso de IAM'?", "opciones": ["To scan IAM policies for syntax errors and violations of best practices / Para escanear las políticas de IAM en busca de errores de sintaxis y violaciones de las mejores prácticas", "To generate IAM policies automatically based on CloudTrail logs / Para generar políticas de IAM automáticamente basadas en los logs de CloudTrail", "To help you identify resources, such as S3 buckets or IAM roles, that are shared with an external entity outside of your zone of trust / Para ayudarte a identificar recursos, como buckets de S3 o roles de IAM, que se comparten con una entidad externa fuera de tu zona de confianza", "To audit password strength and MFA status for all IAM users / Para auditar la fortaleza de las contraseñas y el estado de MFA para todos los usuarios de IAM"], "respuesta_correcta": "To help you identify resources, such as S3 buckets or IAM roles, that are shared with an external entity outside of your zone of trust / Para ayudarte a identificar recursos, como buckets de S3 o roles de IAM, que se comparten con una entidad externa fuera de tu zona de confianza", "explicacion": "Access Analyzer uses formal reasoning to analyze resource-based policies and identify which resources can be accessed from outside your AWS account or organization. It helps you find and remediate unintended external access. / El Analizador de Acceso utiliza el razonamiento formal para analizar las políticas basadas en recursos e identificar qué recursos pueden ser accedidos desde fuera de tu cuenta u organización de AWS. Te ayuda a encontrar y remediar el acceso externo no intencionado." }
    ]
}

